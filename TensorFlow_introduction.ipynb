{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/wdbm/Psychedelic_Machine_Learning_in_the_Cenozoic_Era/master/media/TensorFlow_1.png)\n",
    "\n",
    "This introduction seeks to broach a few basic topics in TensorFlow: what it is, how operations and data are defined for its computational graphs and how its operations are visualized. In doing this, some basic examples are shown, involving linear regression and basic optimizer usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What the shit is TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is an open source software library for numerical computation using data flow graphs. In a data flow graph, nodes represent mathematical operations and edges represent the multidimensional data arrays (tensors) communicated between them.\n",
    "\n",
    "![](https://raw.githubusercontent.com/wdbm/abstraction/master/media/2016-05-14T1754Z.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is usually used in Python, though in the background it is using hardcore efficient code to parallelize its calculations a lot and is well-suited to GPU hardware. The Python convention to import TensorFlow is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be helpful to hide some TensorFlow logging messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.TF_CPP_MIN_LOG_LEVEL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensors, ranks, shapes and types\n",
    "\n",
    "The central unit of data in TensorFlow is the tensor, in the sense of it being an array of some arbitrary dimensionality. A tensor of rank 0 is a scalar, a tensor of rank 1 is a vector, a tensor of rank 2 is a matrix, a tensor of rank 3 is a 3-tensor, and so on.\n",
    "\n",
    "|**rank**|**mathamatical object**|**shape**  |**example**                       |\n",
    "|--------|-----------------------|-----------|----------------------------------|\n",
    "|0       |scalar                 |`[]`       |`3`                               |\n",
    "|1       |vector                 |`[3]`      |`[1. ,2., 3.]`                    |\n",
    "|2       |matrix                 |`[2, 3]`   |`[[1., 2., 3.], [4., 5., 6.]]`    |\n",
    "|3       |3-tensor               |`[2, 1, 3]`|`[[[1., 2., 3.]], [[7., 8., 9.]]]`|\n",
    "|n       |n-tensor               |...        |...                               |\n",
    "\n",
    "The various number types that TensorFlow can handle are as follows:\n",
    "\n",
    "|**data type**|Python type|**description**       |\n",
    "|-------------|-----------|----------------------|\n",
    "|`DT_FLOAT`   |`t.float32`|32 bits floating point|\n",
    "|`DT_DOUBLE`  |`t.float64`|64 bits floating point|\n",
    "|`DT_INT8`    |`t.int8`   |8 bits signed integer |\n",
    "|`DT_INT16`   |`t.int16`  |16 bits signed integer|\n",
    "|`DT_INT32`   |`t.int32`  |32 bits signed integer|\n",
    "|`DT_INT64`   |`t.int64`  |64 bits signed integer|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow mechanics: computational graphs and nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow programs are defined as computational graphs. For TensorFlow, a computational graph is a series of TensorFlow operations arranged in a graph of nodes. A node takes zero or more tensors as inputs and produces a tensor as an output. Generally, a TensorFlow program consists of sections like these:\n",
    "\n",
    "- 1 Build a graph using TensorFlow operations.\n",
    "- 2 Feed data to TensorFlow and run the graph.\n",
    "- 3 Update variables in the graph and return values.\n",
    "\n",
    "A simple TensorFlow node is a constant. It takes no inputs and simply outputs a value that it stores internally. Here are some constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_1: Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "node_2: Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node_1 = tf.constant(3.0, tf.float32)\n",
    "node_2 = tf.constant(4.0) # (also tf.float32 by default)\n",
    "\n",
    "print(\"node_1: {node}\".format(node = node_1))\n",
    "print(\"node_2: {node}\".format(node = node_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printouts of the nodes do not evaluate the outputs the nodes would produce, but show simply what the nodes would evaluate. To evaluate nodes, the computational graph is run in an encapsulation of the control and state of the TensorFlow runtime called a TensorFlow \"session\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Session` is a class for running TensorFlow operations. A session object encapsulates the environment in which operations are executed and tensors are evaluated. For example, `sess.run(c)` evaluates the tensor `c`.\n",
    "\n",
    "A session is run using its `run` method:\n",
    "\n",
    "```Python\n",
    "tf.Session.run(\n",
    "    fetches,\n",
    "    feed_dict    = None,\n",
    "    options      = None,\n",
    "    run_metadata = None\n",
    ")\n",
    "```\n",
    "\n",
    "This method runs operations and evaluates tensors in fetches. It returns one epoch of TensorFlow computation, by running the necessary graph fragment to execute every operation and evaluate every tensor in fetches, substituting the values in `feed_dict` for the corresponding input values. The `fetches` option can be a single graph element, or an arbitrary nested list, tuple, namedtuple, dict or OrderedDict containing graph elements at its leaves. The value returned by `run` has the same shape as the fetches argument, where the leaves are replaced by the corresponding values returned by TensorFlow.\n",
    "\n",
    "So, those constant nodes could be evaluated like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 4.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run([node_1, node_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complicated nodes than constants are operations. For example, two constant nodes could be added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_3 = tf.add(node_1, node_2)\n",
    "\n",
    "node_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(node_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is, of course, a trivial mathematical operation, but it has been performed using very computationally efficient infrastructure. Far more complicated operations can be encoded in a computational graph and run using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computational graph can be parameterized to accept external inputs. These entry points for data are called placeholders.\n",
    "\n",
    "So, let's create some placeholders that can hold 32 bit floating point numbers and let's also make a node for the addition operation applied to these placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "\n",
    "adder_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `feed_dict` parameter of a session `run` method is used to input data to these placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a: 3, b: 4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can be done with multiple values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.  10.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a: [3, 4], b: [5, 6]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start to see now how parallelism is core to TensorFlow.\n",
    "\n",
    "Further nodes can be added to the computational graph easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3.\n",
    "\n",
    "sess.run(add_and_triple, {a: 3, b: 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are nodes that have values that can change. These are used to have variable values in models, to make models trainable. A variable is defined with a type and an initial value.\n",
    "\n",
    "We can make a linear model featuring changable variables like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([  .3], dtype = tf.float32)\n",
    "b = tf.Variable([- .3], dtype = tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants are initialized when they are called and their value doesn't change, but variables are initialized in a TensorFlow program using a special operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `x` is a placeholder, this linear model can be evaluated for several `x` values in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large number of values can be stored in a variable easily, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29038599  0.40005922 -0.0074049  ...,  0.08409318 -0.65591121\n",
      "   0.36056435]\n",
      " [ 0.58701861 -0.44173887 -0.01274026 ...,  0.42211297  0.33497554\n",
      "   0.50231361]\n",
      " [-0.52332699  0.2221975   0.26991877 ...,  0.81112605  0.18078502\n",
      "   0.44949597]\n",
      " ..., \n",
      " [ 0.10706387 -0.58917826 -0.07221451 ..., -0.59688383 -0.12328178\n",
      "  -0.08238212]\n",
      " [ 0.07305962 -0.45373321  0.35089943 ...,  0.09356716  0.14571831\n",
      "   0.0526332 ]\n",
      " [ 0.30902797 -0.41249207  0.41025901 ...,  0.46190271  0.24490891\n",
      "   0.27930591]]\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(\n",
    "    tf.random_normal(\n",
    "        [784, 200],\n",
    "        stddev = 0.35\n",
    "    ),\n",
    "    name = \"weights\"\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(sess.run(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of a variable can be changed using operating like `tf.assign`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial variable value: 10.0\n",
      "reassigned variable value: 20.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(10, dtype = tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"initial variable value: {value}\".format(value = sess.run(a)))\n",
    "    \n",
    "    sess.run(tf.assign(a, 20))\n",
    "\n",
    "    print(\"reassigned variable value: {value}\".format(value = sess.run(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loss function measures how far a model is from provided data. For a linear regression model, a standard loss function is the sums of the squares of the deltas between the current model and the provided data.\n",
    "\n",
    "So, here we create a linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([ .3], dtype = tf.float32)\n",
    "b = tf.Variable([-.3], dtype = tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a placeholder for our target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the loss function for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(linear_model - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We launch a TensorFlow session, initialize graph variables (`W`, `b`), specify the target values (`y`), specify the model parameters to try (`x`) and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    results = sess.run(\n",
    "        loss,\n",
    "        {\n",
    "            x: [1,  2,  3,  4],\n",
    "            y: [0, -1, -2, -3]\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, a simple linear model like this would be modified automatically by changing the variables `W` and `b` to try to find good model parameters. In this example, ideal values would be `W = -1` and `b = 1`, which would result in the loss function being 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers change variables in models in order to minimize loss functions. There is a lot of study ongoing on optimizers and there are many types. A simple optimizer is gradient descent. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable.\n",
    "\n",
    "Let's see the gradient descent optimize our linear regression model. We can do this by defining the optimizer (including its learning rate), defining what it is trying to minimize and then running that minimization in TensorFlow (instead of just running the loss function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        sess.run(\n",
    "            train,\n",
    "            {\n",
    "                x: [1,  2,  3,  4],\n",
    "                y: [0, -1, -2, -3]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the linear model parameters that resulted from this gradient descent minimization, and they are pretty close to `-1` and `-1`, which is cool. Tous en choeur maintenant, the code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969], b: [ 0.99999082], loss: 5.699973826267524e-11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable([ .3], dtype = tf.float32)\n",
    "b = tf.Variable([-.3], dtype = tf.float32)\n",
    "\n",
    "linear_model = W * x + b\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "x_train = [1,  2,  3,  4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        sess.run(\n",
    "            train,\n",
    "            {\n",
    "                x: x_train,\n",
    "                y: y_train\n",
    "            }\n",
    "        )\n",
    "\n",
    "    current_W, current_b, current_loss = sess.run(\n",
    "        [W, b, loss],\n",
    "        {\n",
    "            x: x_train,\n",
    "            y: y_train\n",
    "        }\n",
    "    )\n",
    "    print(\"W: {W}, b: {b}, loss: {loss}\".format(W = current_W, b = current_b, loss = current_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard, basic visualization of training and the minds of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can be logged and viewed in a browser-based learning visualization toolkit called TensorBoard. Scalar tensors are shown as graphs, multidimensional tensors are shown as histograms and images are simply displayed. The computational graph is also displayed. It'd be nifty for t-SNE representations to be added in the future...\n",
    "\n",
    "Some steps in using TensorBoard are as follows:\n",
    "\n",
    "1. Set a path for logging.\n",
    "\n",
    "```Python\n",
    "TB_SUMMARY_DIR = \"/tmp/run\"\n",
    "```\n",
    "\n",
    "2. Set the tensors to log.\n",
    "\n",
    "```Python\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = tf.placeholder(tf.float32)\n",
    "tf.summary.histogram(\"input\", x)\n",
    "```\n",
    "\n",
    "3. Merge the summaries.\n",
    "\n",
    "```Python\n",
    "summary_operation = tf.summary.merge_all()\n",
    "```\n",
    "\n",
    "4. Create a summary writer and add the TensorFlow graph.\n",
    "\n",
    "```Python\n",
    "writer = tf.summary.FileWriter(TB_SUMMARY_DIR)\n",
    "writer.add_graph(sess.graph)\n",
    "```\n",
    "\n",
    "5. During training, run the summary merge operating and add the summary to the summary writer (save to log).\n",
    "\n",
    "\n",
    "```Python\n",
    "_, summary = sess.run([optimizer, summary], feed_dict = feed_dict)\n",
    "writer.add_summary(summary, step)\n",
    "```\n",
    "\n",
    "6. Clear existing logs, launch TensorBoard and run the training.\n",
    "\n",
    "```Bash\n",
    "rm -rf /tmp/run\n",
    "tensorboard --logdir=/tmp/run\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969], b: [ 0.99999082], loss: 5.699973826267524e-11\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "path_logs = \"/tmp/run\"\n",
    "subprocess.Popen([\"killall tensorboard\"],                                            shell = True)\n",
    "subprocess.Popen([\"rm -rf {path_logs}\".format(path_logs = path_logs)],               shell = True)\n",
    "subprocess.Popen([\"tensorboard --logdir={path_logs}\".format(path_logs = path_logs)], shell = True)\n",
    "subprocess.Popen([\"xdg-open http://127.0.1.1:6006\"],                                 shell = True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = tf.placeholder(tf.float32)\n",
    "tf.summary.histogram(\"input\", x)\n",
    "\n",
    "with tf.name_scope(\"architecture\"):\n",
    "    W = tf.Variable([ .3], dtype = tf.float32)\n",
    "    b = tf.Variable([-.3], dtype = tf.float32)\n",
    "    linear_model = W * x + b\n",
    "tf.summary.histogram(\"W\", W)\n",
    "tf.summary.histogram(\"b\", b)\n",
    "tf.summary.histogram(\"linear_model\", linear_model)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_sum(tf.square(linear_model - y))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "x_train = [1,  2,  3,  4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "summary_operation = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(path_logs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        _, summary = sess.run(\n",
    "            [train, summary_operation],\n",
    "            {\n",
    "                x: x_train,\n",
    "                y: y_train\n",
    "            }\n",
    "        )\n",
    "\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    current_W, current_b, current_loss = sess.run(\n",
    "        [W, b, loss],\n",
    "        {\n",
    "            x: x_train,\n",
    "            y: y_train\n",
    "        }\n",
    "    )\n",
    "    print(\"W: {W}, b: {b}, loss: {loss}\".format(W = current_W, b = current_b, loss = current_loss))\n",
    "\n",
    "subprocess.Popen([\"killall tensorboard\"], shell = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard example graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/wdbm/Psychedelic_Machine_Learning_in_the_Cenozoic_Era/master/media/TensorBoard_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard example histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the linear model histogram can be seen approaching the defined target values (-0, -1, -2, -3).\n",
    "\n",
    "![](https://raw.githubusercontent.com/wdbm/Psychedelic_Machine_Learning_in_the_Cenozoic_Era/master/media/TensorBoard_2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
