{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Dense, Dropout, Activation, LSTM, CuDNNLSTM, concatenate, Flatten,\n",
    "                          BatchNormalization, RepeatVector, TimeDistributed, Conv1D, MaxPooling1D)\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tools import SequenceFrame, plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "main_df = pd.read_csv('main_df.csv')\n",
    "main_df.sort_values(by='time', ascending=True)\n",
    "main_df = main_df.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input arrays for LSTM sequence training\n",
    "sf = SequenceFrame(main_df,\n",
    "                   forecast_vars=[f'{RATIO_TO_PREDICT}_close'],\n",
    "                   reflection_vars=['.*'], # f'^((?!{RATIO_TO_PREDICT}).)*$'\n",
    "                   forecast_steps=FUTURE_PERIOD_PREDICT,\n",
    "                   reflection_steps=SEQ_LEN,\n",
    "                   t0_past=True)\n",
    "\n",
    "#print(\"using previous measurements:\\n\", sf.reflected_columns, \"\\n\")\n",
    "#print(\"to predict:\\n\", sf.forecasted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dfs of predictions and past sequence data, which will be reshaped\n",
    "df_forecasted, df_reflected = sf.split_sequence_data()\n",
    "\n",
    "# for parity, predict 3 timesteps in the future\n",
    "df_forecasted = df_forecasted[[f'LTC-USD_close_t+{FUTURE_PERIOD_PREDICT}']]\n",
    "\n",
    "# convert the future price values into higher (1) or lower (0) labels relative to most recent observed timestep\n",
    "_df = pd.DataFrame()\n",
    "target_columns = []\n",
    "initial_columns = df_forecasted.columns\n",
    "\n",
    "for c in initial_columns:\n",
    "    target_columns.append(f'{c}_higher')\n",
    "    _df[f'{c}_higher'] = (df_forecasted[c] > df_reflected[f'{RATIO_TO_PREDICT}_close_t']).astype(int) # 'current'\n",
    "    df_forecasted = df_forecasted.join(_df)\n",
    "else:\n",
    "    df_forecasted.drop(initial_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale other prices to pct differences\n",
    "for c in df_reflected.columns:\n",
    "    df_reflected[c] = df_reflected[c].pct_change()\n",
    "df_reflected.dropna(inplace=True)\n",
    "for c in df_reflected.columns:\n",
    "    df_reflected[c] = preprocessing.scale(df_reflected[c].values)\n",
    "    \n",
    "# get rid of first row of forecasts now\n",
    "df_forecasted = df_forecasted.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97660, 480)\n",
      "(97660, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df_reflected.shape)\n",
    "print(df_forecasted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here, split away some slice of the future data from the main dfs.\n",
    "validation_frac = 0.2\n",
    "split_ind = int((1-validation_frac)*len(df_reflected))\n",
    "\n",
    "training_input = df_reflected[:split_ind].values\n",
    "training_output = df_forecasted[:split_ind].values\n",
    "validation_input = df_reflected[split_ind:].values\n",
    "validation_output = df_forecasted[split_ind:].values\n",
    "\n",
    "training_input = training_input.reshape((training_input.shape[0], SEQ_LEN, len(sf.reflection_vars)))\n",
    "validation_input = validation_input.reshape((validation_input.shape[0], SEQ_LEN, len(sf.reflection_vars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78128, 60, 8) (78128, 1)\n",
      "(19532, 60, 8) (19532, 1)\n"
     ]
    }
   ],
   "source": [
    "print(training_input.shape, training_output.shape)\n",
    "print(validation_input.shape, validation_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4540544  -0.08328593 -0.74516098 -0.00811349 -0.64585383 -0.00582664\n",
      " -0.01345761 -0.0534055 ]\n",
      "\n",
      "BTC-USD_close_t-59    -1.454054\n",
      "BTC-USD_volume_t-59   -0.083286\n",
      "LTC-USD_close_t-59    -0.745161\n",
      "LTC-USD_volume_t-59   -0.008113\n",
      "BCH-USD_close_t-59    -0.645854\n",
      "BCH-USD_volume_t-59   -0.005827\n",
      "ETH-USD_close_t-59    -0.013458\n",
      "ETH-USD_volume_t-59   -0.053405\n",
      "Name: 1528972320, dtype: float64\n",
      "\n",
      "[0]\n",
      "\n",
      "96.589996\n",
      "96.400002\n"
     ]
    }
   ],
   "source": [
    "# sanity check - first element of first input array is the set of 8 variables at the earliest timestep \n",
    "print(training_input[0,0])\n",
    "print(\"\")\n",
    "print(df_reflected.iloc[0][:8])\n",
    "print(\"\")\n",
    "\n",
    "# the output 0 implies price should go down\n",
    "print(training_output[0])\n",
    "print(\"\")\n",
    "print(main_df.iloc[SEQ_LEN]['LTC-USD_close'])\n",
    "print(main_df.iloc[SEQ_LEN+FUTURE_PERIOD_PREDICT]['LTC-USD_close']) # confirm: should be lower FUTURE_PERIOD_PREDICT timesteps later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buys, sales (training):\n",
      "32471 45657\n",
      "buys, sales (validation):\n",
      "8437 11095\n"
     ]
    }
   ],
   "source": [
    "# we want the same number of buys and sells, so we have to cut out some of our data according to which appears the least\n",
    "# (first index is first axis - the number of samples)\n",
    "buy_inds_train, sell_inds_train = np.where(training_output == [1])[0], np.where(training_output == [0])[0]\n",
    "buy_inds_validation, sell_inds_validation = np.where(validation_output == [1])[0], np.where(validation_output == [0])[0]\n",
    "\n",
    "# get the total numbers \n",
    "total_buys_train, total_buys_validation = len(buy_inds_train), len(buy_inds_validation)\n",
    "total_sales_train, total_sales_validation = len(sell_inds_train), len(sell_inds_validation)\n",
    "\n",
    "# the minimum in each dataset is the total number we use\n",
    "n_use_train, n_use_validation = min(total_buys_train, total_sales_train), min(total_buys_validation, total_sales_validation)\n",
    "\n",
    "print(\"buys, sales (training):\")\n",
    "print(total_buys_train, total_sales_train)\n",
    "print(\"buys, sales (validation):\")\n",
    "print(total_buys_validation, total_sales_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut down our inputs to equalise buys and sells\n",
    "training_input_lstm = np.concatenate(\n",
    "    (training_input[buy_inds_train[:n_use_train]], training_input[sell_inds_train[:n_use_train]]))\n",
    "training_output_lstm = np.concatenate(\n",
    "    (training_output[buy_inds_train[:n_use_train]], training_output[sell_inds_train[:n_use_train]]))\n",
    "validation_input_lstm = np.concatenate(\n",
    "    (validation_input[buy_inds_validation[:n_use_validation]], validation_input[sell_inds_validation[:n_use_validation]]))\n",
    "validation_output_lstm = np.concatenate(\n",
    "    (validation_output[buy_inds_validation[:n_use_validation]], validation_output[sell_inds_validation[:n_use_validation]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle inputs and outputs by same random permutation\n",
    "trn_shuff_perm = np.random.permutation(training_input_lstm.shape[0])\n",
    "val_shuff_perm = np.random.permutation(validation_input_lstm.shape[0])\n",
    "\n",
    "# shuffle\n",
    "training_input_lstm = training_input_lstm[trn_shuff_perm]\n",
    "training_output_lstm = training_output_lstm[trn_shuff_perm]\n",
    "validation_input_lstm = validation_input_lstm[val_shuff_perm]\n",
    "validation_output_lstm = validation_output_lstm[val_shuff_perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# board the CUDA train to seshlehem\n",
    "try:\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    assert K.tensorflow_backend._get_available_gpus()\n",
    "except:\n",
    "    print(\"whoops, someone needs to buy a GPU...\")\n",
    "    print(\"make sure to go AFK for a while.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 1 - vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(LSTM_nodes = 200,\n",
    "                     dense_nodes = 50,\n",
    "                     LSTM_layers = 3,\n",
    "                     dense_layers = 1,\n",
    "                     activation = 'relu',\n",
    "                     dropout = 0.2,\n",
    "                     input_dim=training_input_lstm.shape[-1],\n",
    "                     reflection_steps=training_input_lstm.shape[1],\n",
    "                     output_dim=training_output_lstm.shape[1],\n",
    "                     regress=True):\n",
    "    \"\"\" build LSTM model \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    rs = True if LSTM_layers > 1 else False\n",
    "    model.add(CuDNNLSTM(LSTM_nodes,\n",
    "                        input_shape=(reflection_steps, input_dim),\n",
    "                        return_sequences=rs))\n",
    "    model.add(Dropout(dropout))\n",
    "    for l in range(LSTM_layers-1):\n",
    "        rs = False if l == LSTM_layers-2 else True\n",
    "        model.add(CuDNNLSTM(LSTM_nodes, return_sequences=rs))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(dense_nodes, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    for l in range(dense_layers-1):\n",
    "        model.add(Dense(dense_nodes, activation=activation))\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "    # connect to outputs if not using as part of a multi-input network\n",
    "    if regress:\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "# network hyperparameters\n",
    "LSTM_nodes = 128\n",
    "dense_nodes = 32\n",
    "LSTM_layers = 3\n",
    "dense_layers = 1\n",
    "activation = 'relu'\n",
    "dropout = 0.2\n",
    "\n",
    "# training parameters\n",
    "epochs = 100\n",
    "batch_size = 50\n",
    "validation_split = 0.2\n",
    "\n",
    "# compile model\n",
    "lstm_model = build_lstm_model(LSTM_nodes = LSTM_nodes,\n",
    "                             dense_nodes = dense_nodes,\n",
    "                             LSTM_layers = LSTM_layers,\n",
    "                             dense_layers = dense_layers,\n",
    "                             activation = activation,\n",
    "                             dropout = dropout,\n",
    "                             regress=True)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "lstm_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "name = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-LSTM-{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "filepath = \"LSTM-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath,\n",
    "                                                      monitor='val_acc',\n",
    "                                                      verbose=1,\n",
    "                                                      save_best_only=True,\n",
    "                                                      mode='max')) # saves only the best ones\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64942 samples, validate on 16874 samples\n",
      "Epoch 1/100\n",
      "64942/64942 [==============================] - 30s 457us/step - loss: 0.6854 - acc: 0.5435 - val_loss: 0.7167 - val_acc: 0.4960\n",
      "Epoch 2/100\n",
      "64942/64942 [==============================] - 25s 381us/step - loss: 0.6640 - acc: 0.5813 - val_loss: 0.7010 - val_acc: 0.5152\n",
      "Epoch 3/100\n",
      "64942/64942 [==============================] - 25s 379us/step - loss: 0.6522 - acc: 0.5920 - val_loss: 0.7368 - val_acc: 0.5235\n",
      "Epoch 4/100\n",
      "64942/64942 [==============================] - 25s 381us/step - loss: 0.6414 - acc: 0.6048 - val_loss: 0.7710 - val_acc: 0.5215\n",
      "Epoch 5/100\n",
      "64942/64942 [==============================] - 25s 380us/step - loss: 0.6353 - acc: 0.6132 - val_loss: 0.8064 - val_acc: 0.5291\n",
      "Epoch 6/100\n",
      "64942/64942 [==============================] - 25s 379us/step - loss: 0.6270 - acc: 0.6196 - val_loss: 0.8982 - val_acc: 0.5286\n",
      "Epoch 7/100\n",
      "64942/64942 [==============================] - 25s 379us/step - loss: 0.6204 - acc: 0.6252 - val_loss: 0.8720 - val_acc: 0.5316\n",
      "Epoch 8/100\n",
      "64942/64942 [==============================] - 25s 381us/step - loss: 0.6132 - acc: 0.6319 - val_loss: 0.9263 - val_acc: 0.5299\n",
      "Epoch 9/100\n",
      "64942/64942 [==============================] - 25s 381us/step - loss: 0.6048 - acc: 0.6394 - val_loss: 0.9918 - val_acc: 0.5270\n",
      "Epoch 10/100\n",
      "64942/64942 [==============================] - 25s 383us/step - loss: 0.5979 - acc: 0.6479 - val_loss: 0.8840 - val_acc: 0.5322\n",
      "Epoch 11/100\n",
      "64942/64942 [==============================] - 25s 382us/step - loss: 0.5902 - acc: 0.6544 - val_loss: 1.0650 - val_acc: 0.5260\n",
      "Epoch 12/100\n",
      "29300/64942 [============>.................] - ETA: 12s - loss: 0.5850 - acc: 0.6589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-25d011aea4f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_input_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_output_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               verbose=1, shuffle=False, callbacks=[early_stop])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# plot history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit network and plot loss\n",
    "ltsm_history = lstm_model.fit(training_input_lstm, training_output_lstm,\n",
    "                              epochs=epochs, batch_size=batch_size,\n",
    "                              validation_data=(validation_input_lstm, validation_output_lstm),\n",
    "                              verbose=1, shuffle=False, callbacks=[early_stop])\n",
    "\n",
    "# plot history\n",
    "plt.plot(ltsm_history.history['acc'], label='train')\n",
    "plt.plot(ltsm_history.history['val_acc'], label='validate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 2 - Encoder-decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64942, 1, 1) (64942, 1)\n",
      "(16874, 1, 1) (16874, 1)\n"
     ]
    }
   ],
   "source": [
    "# seq2seq: need to reshape training/testing output to 3d samples * timesteps * features form!\n",
    "training_output_enc_dec_lstm = training_output_lstm.reshape(\n",
    "    (training_output_lstm.shape[0], 1, training_output_lstm.shape[1]))\n",
    "validation_output_enc_dec_lstm = validation_output_lstm.reshape(\n",
    "    (validation_output_lstm.shape[0], 1, validation_output_lstm.shape[1]))\n",
    "\n",
    "print(training_output_enc_dec_lstm.shape, training_output_lstm.shape)\n",
    "print(validation_output_enc_dec_lstm.shape, validation_output_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enc_dec_lstm_model(LSTM_nodes = 100,\n",
    "                             dense_nodes = 100,\n",
    "                             encoder_LSTM_layers = 2,\n",
    "                             decoder_LSTM_layers = 2,\n",
    "                             dense_layers = 1,\n",
    "                             activation = 'relu',\n",
    "                             dropout = 0.2,\n",
    "                             input_dim=training_input_lstm.shape[1:],\n",
    "                             output_dim=training_output_enc_dec_lstm.shape[-1],\n",
    "                             regress=True):\n",
    "    \"\"\" build encoder-decoder LSTM model\n",
    "        see:\n",
    "            https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/\n",
    "            \n",
    "            https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time\n",
    "            -series-forecasting-of-household-power-consumption/\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    ### encoder ------------------------------------------------------\n",
    "    # learns relationship between steps in input sequence, develops internal representation of these\n",
    "    # 1+ LSTM layers. Outputs fixed-size vector holding internal representation\n",
    "    rs = True if encoder_LSTM_layers > 1 else False\n",
    "    model.add(CuDNNLSTM(LSTM_nodes,\n",
    "                        input_shape=input_dim,\n",
    "                        return_sequences=rs))\n",
    "    model.add(Dropout(dropout))\n",
    "    for l in range(encoder_LSTM_layers-1):\n",
    "        rs = False if l == encoder_LSTM_layers-2 else True # last layer doesn't return seq, just internal vector repr.\n",
    "        model.add(CuDNNLSTM(LSTM_nodes, return_sequences=rs))\n",
    "        model.add(Dropout(dropout))\n",
    "    # internal representation of input sequence repeated multiple times,\n",
    "    # once for each timestep in output sequence. this seq then presented to decoder\n",
    "    # the decoder should map onto an output sequence\n",
    "    # so we need 3D samples * timesteps (output seq) * (latent = n_lstm_nodes) features. \n",
    "    model.add(RepeatVector(training_output_enc_dec_lstm.shape[1])) # repeatvector fits encoder to decoder.\n",
    "\n",
    "    ### decoder ------------------------------------------------------\n",
    "    # converts internal representation into sequence output\n",
    "    # 1+ LSTM layers outputting sequence, once for each forecasted timestep\n",
    "    for l in range(decoder_LSTM_layers):\n",
    "        model.add(CuDNNLSTM(LSTM_nodes, return_sequences=True))\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "    ### output --------------------------------------------------------\n",
    "    # decoder output here is shape: timesteps (output seq) * latent features (for timestep)\n",
    "    # dense layer interprets each timestep in the output sequence one at a time\n",
    "    # to do this use TimeDistributed wrapper, applying the same weights to each step\n",
    "    model.add(TimeDistributed(Dense(dense_nodes, activation=activation)))\n",
    "    model.add(Dropout(dropout))\n",
    "    # output layer (softmax)\n",
    "    # connect to outputs if not using as part of a multi-input network\n",
    "    if regress:\n",
    "        model.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "# network hyperparameters\n",
    "LSTM_nodes = 128\n",
    "dense_nodes = 32\n",
    "encoder_LSTM_layers = 2\n",
    "decoder_LSTM_layers = 2\n",
    "dense_layers = 1\n",
    "activation = 'relu'\n",
    "dropout = 0.3\n",
    "learning_rate=0.0001\n",
    "# training parameters\n",
    "epochs = 25\n",
    "batch_size = 50\n",
    "\n",
    "# build model\n",
    "enc_dec_lstm_model = build_enc_dec_lstm_model(LSTM_nodes = LSTM_nodes,\n",
    "                                              dense_nodes = dense_nodes,\n",
    "                                              encoder_LSTM_layers = encoder_LSTM_layers,\n",
    "                                              decoder_LSTM_layers = decoder_LSTM_layers,\n",
    "                                              dense_layers = dense_layers,\n",
    "                                              activation = activation,\n",
    "                                              dropout = dropout,\n",
    "                                              regress=True)\n",
    "\n",
    "# define callback to force model to stop training if validation loss doesn't improve\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10)\n",
    "opt = keras.optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "enc_dec_lstm_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64942 samples, validate on 16874 samples\n",
      "Epoch 1/25\n",
      "64942/64942 [==============================] - 24s 377us/step - loss: 0.6892 - acc: 0.4995 - val_loss: 0.7005 - val_acc: 0.5007\n",
      "Epoch 2/25\n",
      "64942/64942 [==============================] - 20s 302us/step - loss: 0.6686 - acc: 0.5020 - val_loss: 0.7082 - val_acc: 0.5003\n",
      "Epoch 3/25\n",
      "64942/64942 [==============================] - 20s 300us/step - loss: 0.6619 - acc: 0.5018 - val_loss: 0.7122 - val_acc: 0.4998\n",
      "Epoch 4/25\n",
      "64942/64942 [==============================] - 20s 304us/step - loss: 0.6597 - acc: 0.5013 - val_loss: 0.7135 - val_acc: 0.5005\n",
      "Epoch 5/25\n",
      "64942/64942 [==============================] - 20s 302us/step - loss: 0.6556 - acc: 0.5019 - val_loss: 0.7217 - val_acc: 0.5003\n",
      "Epoch 6/25\n",
      "64942/64942 [==============================] - 19s 300us/step - loss: 0.6536 - acc: 0.5021 - val_loss: 0.7096 - val_acc: 0.5005\n",
      "Epoch 7/25\n",
      "64942/64942 [==============================] - 20s 302us/step - loss: 0.6513 - acc: 0.5020 - val_loss: 0.7149 - val_acc: 0.5004\n",
      "Epoch 8/25\n",
      "64942/64942 [==============================] - 20s 303us/step - loss: 0.6484 - acc: 0.5021 - val_loss: 0.7268 - val_acc: 0.5007\n",
      "Epoch 9/25\n",
      "64942/64942 [==============================] - 20s 303us/step - loss: 0.6463 - acc: 0.5021 - val_loss: 0.7278 - val_acc: 0.5006\n",
      "Epoch 10/25\n",
      "64942/64942 [==============================] - 20s 306us/step - loss: 0.6439 - acc: 0.5018 - val_loss: 0.7631 - val_acc: 0.5006\n",
      "Epoch 11/25\n",
      "64942/64942 [==============================] - 20s 301us/step - loss: 0.6416 - acc: 0.5023 - val_loss: 0.7735 - val_acc: 0.5005\n",
      "Epoch 12/25\n",
      "64942/64942 [==============================] - 20s 306us/step - loss: 0.6384 - acc: 0.5019 - val_loss: 0.8064 - val_acc: 0.5006\n",
      "Epoch 13/25\n",
      "64942/64942 [==============================] - 20s 302us/step - loss: 0.6356 - acc: 0.5020 - val_loss: 0.8176 - val_acc: 0.5007\n",
      "Epoch 14/25\n",
      "64942/64942 [==============================] - 20s 307us/step - loss: 0.6344 - acc: 0.5021 - val_loss: 0.7888 - val_acc: 0.5008\n",
      "Epoch 15/25\n",
      "64942/64942 [==============================] - 20s 304us/step - loss: 0.6311 - acc: 0.5022 - val_loss: 0.8567 - val_acc: 0.5009\n",
      "Epoch 16/25\n",
      "64942/64942 [==============================] - 20s 305us/step - loss: 0.6293 - acc: 0.5022 - val_loss: 0.9025 - val_acc: 0.5009\n",
      "Epoch 17/25\n",
      "64942/64942 [==============================] - 20s 304us/step - loss: 0.6277 - acc: 0.5022 - val_loss: 0.8850 - val_acc: 0.5012\n",
      "Epoch 18/25\n",
      "64942/64942 [==============================] - 20s 304us/step - loss: 0.6248 - acc: 0.5023 - val_loss: 0.9246 - val_acc: 0.5008\n",
      "Epoch 19/25\n",
      "64942/64942 [==============================] - 20s 305us/step - loss: 0.6229 - acc: 0.5027 - val_loss: 0.9043 - val_acc: 0.5006\n",
      "Epoch 20/25\n",
      "64942/64942 [==============================] - 20s 303us/step - loss: 0.6198 - acc: 0.5023 - val_loss: 1.0271 - val_acc: 0.5002\n",
      "Epoch 21/25\n",
      "64942/64942 [==============================] - 20s 305us/step - loss: 0.6178 - acc: 0.5025 - val_loss: 0.9014 - val_acc: 0.5002\n",
      "Epoch 22/25\n",
      "64942/64942 [==============================] - 20s 306us/step - loss: 0.6153 - acc: 0.5027 - val_loss: 1.0440 - val_acc: 0.5003\n",
      "Epoch 23/25\n",
      "64942/64942 [==============================] - 20s 302us/step - loss: 0.6135 - acc: 0.5026 - val_loss: 0.9956 - val_acc: 0.5003\n",
      "Epoch 24/25\n",
      "64942/64942 [==============================] - 20s 307us/step - loss: 0.6100 - acc: 0.5029 - val_loss: 0.9387 - val_acc: 0.5004\n",
      "Epoch 25/25\n",
      "64942/64942 [==============================] - 20s 304us/step - loss: 0.6079 - acc: 0.5029 - val_loss: 0.9884 - val_acc: 0.5005\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "enc_dec_ltsm_history = enc_dec_lstm_model.fit(training_input_lstm, training_output_enc_dec_lstm,\n",
    "                              epochs=epochs, batch_size=batch_size,\n",
    "                              validation_data=(validation_input_lstm, validation_output_enc_dec_lstm),\n",
    "                              verbose=1, shuffle=False, callbacks=[early_stop]) # shuffle _sequences_, not steps\n",
    "\n",
    "# plot history\n",
    "plt.plot(enc_dec_ltsm_history.history['acc'], label='train')\n",
    "plt.plot(enc_dec_ltsm_history.history['val_acc'], label='validate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 3 - CNN-encoder LSTM-decoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64942, 1, 1) (64942, 1)\n",
      "(16874, 1, 1) (16874, 1)\n"
     ]
    }
   ],
   "source": [
    "# seq2seq: need to reshape training/testing output to 3d samples * timesteps * features form!\n",
    "training_output_cnn_lstm = training_output_lstm.reshape(\n",
    "    (training_output_lstm.shape[0], 1, training_output_lstm.shape[1]))\n",
    "validation_output_cnn_lstm = validation_output_lstm.reshape(\n",
    "    (validation_output_lstm.shape[0], 1, validation_output_lstm.shape[1]))\n",
    "\n",
    "print(training_output_cnn_lstm.shape, training_output_lstm.shape)\n",
    "print(validation_output_cnn_lstm.shape, validation_output_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model(training_inputs=training_input_lstm, # these are the same 3D format as lstm\n",
    "                         training_outputs=training_output_cnn_lstm,\n",
    "                         filters=64,\n",
    "                         LSTM_nodes=200,\n",
    "                         dense_nodes=100,\n",
    "                         pool_size=2,\n",
    "                         kernel_size=3,\n",
    "                         activation='relu',\n",
    "                         regress=True):\n",
    "\n",
    "    n_timesteps_in, n_input_features = training_inputs.shape[1], training_inputs.shape[2]\n",
    "    n_timesteps_out, n_output_features = training_outputs.shape[1], training_outputs.shape[2]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    # encoder ------------------------------------------\n",
    "    # read in SEQ_LEN × 8 (input vars) 1D sequences. convolve w/ 64 size-3 (default) filters\n",
    "    # to get new feature map of time series\n",
    "     The Flatten layer will take the single 5×5 map and transform it into a 25-element vector ready for some other layer to deal with, such as a Dense for outputting a prediction.\n",
    "    model.add(Conv1D(filters=filters,\n",
    "                     kernel_size=kernel_size,\n",
    "                     activation=activation,\n",
    "                     input_shape=(n_timesteps_in, n_input_features)))\n",
    "    model.add(Conv1D(filters=filters,\n",
    "                     kernel_size=kernel_size,\n",
    "                     activation=activation))\n",
    "    # MaxPooling1D pools the interpretation into length-2 chunks, reducing output size\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    # Flatten ensures output reduced to 1D to feed into next layer \n",
    "    model.add(Flatten())\n",
    "    # repeat internal representation of features to feed to LSTM decoder\n",
    "    model.add(RepeatVector(n_timesteps_out))\n",
    "    \n",
    "    # decoder --------------------------------------------\n",
    "    # SEE LSTM encoder-decoder\n",
    "    model.add(LSTM(LSTM_nodes, activation=activation, return_sequences=True))\n",
    "    \n",
    "    # dense ---------------------------------------------\n",
    "    model.add(TimeDistributed(Dense(dense_nodes, activation=activation)))\n",
    "    \n",
    "    # output ---------------------------------------------\n",
    "    if regress:\n",
    "        model.add(TimeDistributed(Dense(2, activation='softmax'))) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "# network hyperparameters\n",
    "filters = 64\n",
    "dense_nodes = 32\n",
    "LSTM_nodes = 200\n",
    "encoder_LSTM_layers = 2\n",
    "decoder_LSTM_layers = 2\n",
    "dense_layers = 1\n",
    "pool_size = 2\n",
    "kernel_size = 3\n",
    "activation = 'relu'\n",
    "dropout = 0.3\n",
    "learning_rate=0.0001\n",
    "# training parameters\n",
    "epochs = 25\n",
    "batch_size = 50\n",
    "\n",
    "# build model\n",
    "cnn_lstm_model = build_cnn_lstm_model(training_inputs=training_input_lstm, # these are the same 3D format as lstm\n",
    "                                      training_outputs=training_output_cnn_lstm,\n",
    "                                      filters=filters,\n",
    "                                      LSTM_nodes=LSTM_nodes,\n",
    "                                      dense_nodes=dense_nodes,\n",
    "                                      pool_size=pool_size,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      activation=activation)\n",
    "\n",
    "# define callback to force model to stop training if validation loss doesn't improve\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10)\n",
    "opt = keras.optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "cnn_lstm_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64942 samples, validate on 16874 samples\n",
      "Epoch 1/25\n",
      " 6400/64942 [=>............................] - ETA: 10s - loss: 0.0856 - acc: 0.5106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c5fcebb5d444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn_lstm_history = cnn_lstm_model.fit(training_input_lstm, training_output_cnn_lstm, epochs=epochs, batch_size=batch_size,\n\u001b[0;32m----> 2\u001b[0;31m                                       validation_data=(validation_input_lstm, validation_output_cnn_lstm))\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_lstm_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_lstm_history = cnn_lstm_model.fit(training_input_lstm, training_output_cnn_lstm, epochs=epochs, batch_size=batch_size,\n",
    "                                      validation_data=(validation_input_lstm, validation_output_cnn_lstm))\n",
    "\n",
    "# plot history\n",
    "plt.plot(cnn_lstm_history.history['acc'], label='train')\n",
    "plt.plot(cnn_lstm_history.history['val_acc'], label='validate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
