{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example: Keras 1D convolutional neural network on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'iris.csv',\n",
    "    header = None,\n",
    "    names  = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df['species'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df['labels']\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.asarray(x), np.asarray(y), test_size = 0.33, shuffle = True)\n",
    "num_classes = 3\n",
    "input_shape = (4,)\n",
    "\n",
    "# Convert class vectors to binary class matrices using 1 hot encoding.\n",
    "y_train_binary = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_binary  = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.reshape(100, 4, 1)\n",
    "x_test  = x_test.reshape(50, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 2, 32)             128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 3,731\n",
      "Trainable params: 3,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(\n",
    "    32,\n",
    "    (3),\n",
    "    input_shape = (4, 1),\n",
    "    activation  = 'relu'\n",
    "))\n",
    "model.add(\n",
    "    MaxPooling1D(\n",
    "        pool_size   = (2)\n",
    "    )\n",
    ")\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate = 0.5))\n",
    "model.add(Dense(\n",
    "    100,\n",
    "    activation  = 'relu'\n",
    "))\n",
    "model.add(Dense(\n",
    "    num_classes,\n",
    "    activation  = 'softmax'\n",
    "))\n",
    "model.compile(\n",
    "    loss            = \"categorical_crossentropy\",\n",
    "    optimizer       = \"adam\",\n",
    "    metrics         = ['accuracy']\n",
    ")\n",
    "plot_model(model, to_file=\"model.png\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback class which is to be passed to the model fitting function\n",
    "# as an element of a list of possible callbacks.\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.acc = []\n",
    "    def on_epoch_end(self, batch, logs = {}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#    filepath       = 'best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "#    monitor        = 'val_loss',\n",
    "#    save_best_only = True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.1897 - acc: 0.3200 - val_loss: 1.0683 - val_acc: 0.3200\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 1.1266 - acc: 0.3000 - val_loss: 1.0548 - val_acc: 0.3200\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 1.0832 - acc: 0.4000 - val_loss: 1.0430 - val_acc: 0.3200\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 1.0685 - acc: 0.4400 - val_loss: 1.0333 - val_acc: 0.3200\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 1.0314 - acc: 0.4700 - val_loss: 1.0240 - val_acc: 0.3200\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 1.0498 - acc: 0.4300 - val_loss: 1.0152 - val_acc: 0.3200\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 1.0456 - acc: 0.4300 - val_loss: 1.0064 - val_acc: 0.3200\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 1.0211 - acc: 0.4500 - val_loss: 0.9980 - val_acc: 0.3200\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 1.0093 - acc: 0.4800 - val_loss: 0.9899 - val_acc: 0.3400\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 1.0547 - acc: 0.4000 - val_loss: 0.9813 - val_acc: 0.3400\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.9882 - acc: 0.4800 - val_loss: 0.9713 - val_acc: 0.3400\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 1.0157 - acc: 0.4500 - val_loss: 0.9611 - val_acc: 0.3400\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.9650 - acc: 0.5200 - val_loss: 0.9502 - val_acc: 0.3600\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.9851 - acc: 0.4500 - val_loss: 0.9402 - val_acc: 0.4400\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.9263 - acc: 0.6000 - val_loss: 0.9291 - val_acc: 0.6200\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.9834 - acc: 0.4600 - val_loss: 0.9182 - val_acc: 0.7000\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.9601 - acc: 0.5000 - val_loss: 0.9064 - val_acc: 0.7200\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.9446 - acc: 0.5000 - val_loss: 0.8947 - val_acc: 0.7000\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.9467 - acc: 0.5200 - val_loss: 0.8834 - val_acc: 0.7000\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.9158 - acc: 0.5900 - val_loss: 0.8718 - val_acc: 0.7000\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.9336 - acc: 0.5200 - val_loss: 0.8601 - val_acc: 0.7000\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.9053 - acc: 0.6000 - val_loss: 0.8487 - val_acc: 0.7000\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.8671 - acc: 0.6000 - val_loss: 0.8368 - val_acc: 0.7000\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.8849 - acc: 0.6500 - val_loss: 0.8253 - val_acc: 0.7000\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.8701 - acc: 0.6200 - val_loss: 0.8146 - val_acc: 0.7000\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.8732 - acc: 0.5700 - val_loss: 0.8041 - val_acc: 0.7000\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.8652 - acc: 0.6100 - val_loss: 0.7939 - val_acc: 0.7000\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.8693 - acc: 0.5700 - val_loss: 0.7833 - val_acc: 0.7000\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.8652 - acc: 0.5700 - val_loss: 0.7726 - val_acc: 0.7200\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.7863 - acc: 0.6200 - val_loss: 0.7622 - val_acc: 0.7200\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.8435 - acc: 0.5900 - val_loss: 0.7525 - val_acc: 0.7200\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.7709 - acc: 0.6900 - val_loss: 0.7427 - val_acc: 0.7200\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.8744 - acc: 0.5400 - val_loss: 0.7332 - val_acc: 0.7400\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.8341 - acc: 0.6300 - val_loss: 0.7237 - val_acc: 0.7400\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.8118 - acc: 0.6800 - val_loss: 0.7138 - val_acc: 0.7400\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.8095 - acc: 0.6200 - val_loss: 0.7036 - val_acc: 0.7400\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.7744 - acc: 0.6300 - val_loss: 0.6932 - val_acc: 0.7400\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.8238 - acc: 0.6000 - val_loss: 0.6832 - val_acc: 0.7400\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.7882 - acc: 0.6600 - val_loss: 0.6739 - val_acc: 0.7400\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.7272 - acc: 0.7200 - val_loss: 0.6648 - val_acc: 0.7400\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.7432 - acc: 0.6500 - val_loss: 0.6557 - val_acc: 0.7400\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.7584 - acc: 0.6600 - val_loss: 0.6469 - val_acc: 0.7400\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.7597 - acc: 0.6300 - val_loss: 0.6388 - val_acc: 0.7600\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.7504 - acc: 0.6600 - val_loss: 0.6312 - val_acc: 0.7600\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.7191 - acc: 0.6800 - val_loss: 0.6237 - val_acc: 0.8000\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.7170 - acc: 0.6700 - val_loss: 0.6161 - val_acc: 0.8000\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.6727 - acc: 0.7600 - val_loss: 0.6083 - val_acc: 0.8000\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.7088 - acc: 0.6700 - val_loss: 0.6008 - val_acc: 0.8000\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.7138 - acc: 0.6300 - val_loss: 0.5937 - val_acc: 0.8200\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.7045 - acc: 0.6600 - val_loss: 0.5863 - val_acc: 0.8400\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.7412 - acc: 0.6000 - val_loss: 0.5793 - val_acc: 0.8800\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6906 - acc: 0.6900 - val_loss: 0.5724 - val_acc: 0.8800\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.6684 - acc: 0.6900 - val_loss: 0.5655 - val_acc: 0.8800\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.6709 - acc: 0.7300 - val_loss: 0.5588 - val_acc: 0.8800\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.6584 - acc: 0.7700 - val_loss: 0.5519 - val_acc: 0.8800\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6792 - acc: 0.6900 - val_loss: 0.5450 - val_acc: 0.8400\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6485 - acc: 0.6800 - val_loss: 0.5386 - val_acc: 0.8400\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.6739 - acc: 0.6900 - val_loss: 0.5325 - val_acc: 0.8400\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6326 - acc: 0.7100 - val_loss: 0.5255 - val_acc: 0.8400\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.6039 - acc: 0.7300 - val_loss: 0.5189 - val_acc: 0.8400\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.5654 - acc: 0.8000 - val_loss: 0.5122 - val_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.6142 - acc: 0.7100 - val_loss: 0.5056 - val_acc: 0.8400\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6012 - acc: 0.7400 - val_loss: 0.4990 - val_acc: 0.8400\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.5734 - acc: 0.8200 - val_loss: 0.4922 - val_acc: 0.8600\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.6412 - acc: 0.6800 - val_loss: 0.4854 - val_acc: 0.8800\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.5630 - acc: 0.8200 - val_loss: 0.4787 - val_acc: 0.8800\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6036 - acc: 0.7500 - val_loss: 0.4724 - val_acc: 0.8800\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6077 - acc: 0.6500 - val_loss: 0.4664 - val_acc: 0.9000\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.5552 - acc: 0.8100 - val_loss: 0.4605 - val_acc: 0.9200\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.5659 - acc: 0.7600 - val_loss: 0.4546 - val_acc: 0.9400\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.5773 - acc: 0.7700 - val_loss: 0.4491 - val_acc: 0.9400\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.5461 - acc: 0.7300 - val_loss: 0.4436 - val_acc: 0.9400\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.5906 - acc: 0.7100 - val_loss: 0.4379 - val_acc: 0.9400\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.5482 - acc: 0.8200 - val_loss: 0.4321 - val_acc: 0.9200\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.5360 - acc: 0.7500 - val_loss: 0.4263 - val_acc: 0.9200\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.5781 - acc: 0.7300 - val_loss: 0.4206 - val_acc: 0.9200\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.5438 - acc: 0.7700 - val_loss: 0.4151 - val_acc: 0.9000\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.5433 - acc: 0.7800 - val_loss: 0.4097 - val_acc: 0.9000\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.5812 - acc: 0.6800 - val_loss: 0.4048 - val_acc: 0.9000\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.5174 - acc: 0.7700 - val_loss: 0.4004 - val_acc: 0.8800\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.5094 - acc: 0.8300 - val_loss: 0.3962 - val_acc: 0.8800\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.5031 - acc: 0.7800 - val_loss: 0.3922 - val_acc: 0.8800\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.5294 - acc: 0.8200 - val_loss: 0.3882 - val_acc: 0.8800\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.5320 - acc: 0.7500 - val_loss: 0.3842 - val_acc: 0.8800\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.4740 - acc: 0.8200 - val_loss: 0.3802 - val_acc: 0.9000\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.5165 - acc: 0.8200 - val_loss: 0.3764 - val_acc: 0.9200\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.5230 - acc: 0.7400 - val_loss: 0.3728 - val_acc: 0.9400\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.5404 - acc: 0.7700 - val_loss: 0.3694 - val_acc: 0.9600\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.4751 - acc: 0.8300 - val_loss: 0.3661 - val_acc: 0.9600\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4409 - acc: 0.8500 - val_loss: 0.3629 - val_acc: 0.9600\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4983 - acc: 0.8000 - val_loss: 0.3595 - val_acc: 0.9600\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.5120 - acc: 0.7400 - val_loss: 0.3564 - val_acc: 0.9600\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.4951 - acc: 0.7600 - val_loss: 0.3532 - val_acc: 0.9600\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.4712 - acc: 0.8400 - val_loss: 0.3499 - val_acc: 0.9600\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.5100 - acc: 0.7400 - val_loss: 0.3466 - val_acc: 0.9600\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4788 - acc: 0.7800 - val_loss: 0.3435 - val_acc: 0.9400\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.4615 - acc: 0.7700 - val_loss: 0.3405 - val_acc: 0.9400\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.4353 - acc: 0.8600 - val_loss: 0.3376 - val_acc: 0.9400\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4592 - acc: 0.8200 - val_loss: 0.3346 - val_acc: 0.9400\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4670 - acc: 0.7700 - val_loss: 0.3317 - val_acc: 0.9400\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4526 - acc: 0.7900 - val_loss: 0.3289 - val_acc: 0.9200\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.4222 - acc: 0.8600 - val_loss: 0.3264 - val_acc: 0.9200\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4483 - acc: 0.8100 - val_loss: 0.3240 - val_acc: 0.9200\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.4984 - acc: 0.7400 - val_loss: 0.3218 - val_acc: 0.9200\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4691 - acc: 0.8100 - val_loss: 0.3194 - val_acc: 0.9200\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4790 - acc: 0.7800 - val_loss: 0.3171 - val_acc: 0.9400\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.4568 - acc: 0.7800 - val_loss: 0.3144 - val_acc: 0.9400\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.4762 - acc: 0.7600 - val_loss: 0.3118 - val_acc: 0.9600\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4732 - acc: 0.7500 - val_loss: 0.3097 - val_acc: 0.9600\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.4715 - acc: 0.7700 - val_loss: 0.3081 - val_acc: 0.9600\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.4971 - acc: 0.7800 - val_loss: 0.3066 - val_acc: 0.9400\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4147 - acc: 0.8700 - val_loss: 0.3049 - val_acc: 0.9600\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.4329 - acc: 0.7900 - val_loss: 0.3030 - val_acc: 0.9600\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.4052 - acc: 0.8800 - val_loss: 0.3006 - val_acc: 0.9600\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.4065 - acc: 0.8500 - val_loss: 0.2981 - val_acc: 0.9600\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.4170 - acc: 0.8200 - val_loss: 0.2956 - val_acc: 0.9600\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4389 - acc: 0.8100 - val_loss: 0.2931 - val_acc: 0.9600\n",
      "Epoch 118/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4282 - acc: 0.7900 - val_loss: 0.2908 - val_acc: 0.9600\n",
      "Epoch 119/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.4410 - acc: 0.8200 - val_loss: 0.2885 - val_acc: 0.9600\n",
      "Epoch 120/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.3733 - acc: 0.9000 - val_loss: 0.2861 - val_acc: 0.9600\n",
      "Epoch 121/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.4035 - acc: 0.8500 - val_loss: 0.2836 - val_acc: 0.9600\n",
      "Epoch 122/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.4019 - acc: 0.8700 - val_loss: 0.2811 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.4364 - acc: 0.8100 - val_loss: 0.2789 - val_acc: 0.9600\n",
      "Epoch 124/500\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.4061 - acc: 0.8500 - val_loss: 0.2769 - val_acc: 0.9600\n",
      "Epoch 125/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.3861 - acc: 0.8600 - val_loss: 0.2751 - val_acc: 0.9600\n",
      "Epoch 126/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.4434 - acc: 0.8000 - val_loss: 0.2733 - val_acc: 0.9400\n",
      "Epoch 127/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3677 - acc: 0.8500 - val_loss: 0.2710 - val_acc: 0.9400\n",
      "Epoch 128/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.4334 - acc: 0.8100 - val_loss: 0.2688 - val_acc: 0.9400\n",
      "Epoch 129/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.3979 - acc: 0.8100 - val_loss: 0.2661 - val_acc: 0.9600\n",
      "Epoch 130/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.3748 - acc: 0.8800 - val_loss: 0.2631 - val_acc: 0.9600\n",
      "Epoch 131/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.3921 - acc: 0.8300 - val_loss: 0.2606 - val_acc: 0.9600\n",
      "Epoch 132/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.4077 - acc: 0.8300 - val_loss: 0.2586 - val_acc: 0.9600\n",
      "Epoch 133/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.3807 - acc: 0.8400 - val_loss: 0.2566 - val_acc: 0.9600\n",
      "Epoch 134/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.4188 - acc: 0.8200 - val_loss: 0.2545 - val_acc: 0.9600\n",
      "Epoch 135/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3918 - acc: 0.8400 - val_loss: 0.2529 - val_acc: 0.9600\n",
      "Epoch 136/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.4054 - acc: 0.8600 - val_loss: 0.2518 - val_acc: 0.9600\n",
      "Epoch 137/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.4078 - acc: 0.8000 - val_loss: 0.2508 - val_acc: 0.9600\n",
      "Epoch 138/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.3646 - acc: 0.8400 - val_loss: 0.2493 - val_acc: 0.9600\n",
      "Epoch 139/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.4048 - acc: 0.8200 - val_loss: 0.2481 - val_acc: 0.9600\n",
      "Epoch 140/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.3885 - acc: 0.8600 - val_loss: 0.2466 - val_acc: 0.9600\n",
      "Epoch 141/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.3456 - acc: 0.8700 - val_loss: 0.2448 - val_acc: 0.9600\n",
      "Epoch 142/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.3912 - acc: 0.8600 - val_loss: 0.2435 - val_acc: 0.9600\n",
      "Epoch 143/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.3416 - acc: 0.8800 - val_loss: 0.2424 - val_acc: 0.9600\n",
      "Epoch 144/500\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.3664 - acc: 0.8700 - val_loss: 0.2413 - val_acc: 0.9600\n",
      "Epoch 145/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3781 - acc: 0.8700 - val_loss: 0.2403 - val_acc: 0.9600\n",
      "Epoch 146/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.3599 - acc: 0.8700 - val_loss: 0.2391 - val_acc: 0.9600\n",
      "Epoch 147/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3831 - acc: 0.8400 - val_loss: 0.2378 - val_acc: 0.9600\n",
      "Epoch 148/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3575 - acc: 0.8800 - val_loss: 0.2362 - val_acc: 0.9600\n",
      "Epoch 149/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.3497 - acc: 0.8900 - val_loss: 0.2341 - val_acc: 0.9600\n",
      "Epoch 150/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3629 - acc: 0.8800 - val_loss: 0.2321 - val_acc: 0.9600\n",
      "Epoch 151/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3797 - acc: 0.8700 - val_loss: 0.2310 - val_acc: 0.9600\n",
      "Epoch 152/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.3481 - acc: 0.8400 - val_loss: 0.2301 - val_acc: 0.9600\n",
      "Epoch 153/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.3638 - acc: 0.8600 - val_loss: 0.2291 - val_acc: 0.9600\n",
      "Epoch 154/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3415 - acc: 0.9100 - val_loss: 0.2276 - val_acc: 0.9600\n",
      "Epoch 155/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3743 - acc: 0.8300 - val_loss: 0.2259 - val_acc: 0.9600\n",
      "Epoch 156/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3152 - acc: 0.9200 - val_loss: 0.2236 - val_acc: 0.9600\n",
      "Epoch 157/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.3403 - acc: 0.8700 - val_loss: 0.2211 - val_acc: 0.9600\n",
      "Epoch 158/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.3570 - acc: 0.8300 - val_loss: 0.2184 - val_acc: 0.9600\n",
      "Epoch 159/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.3304 - acc: 0.8900 - val_loss: 0.2146 - val_acc: 0.9600\n",
      "Epoch 160/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.3639 - acc: 0.8300 - val_loss: 0.2113 - val_acc: 0.9800\n",
      "Epoch 161/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.3439 - acc: 0.8500 - val_loss: 0.2092 - val_acc: 0.9600\n",
      "Epoch 162/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.3348 - acc: 0.9000 - val_loss: 0.2081 - val_acc: 0.9600\n",
      "Epoch 163/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3191 - acc: 0.9300 - val_loss: 0.2073 - val_acc: 0.9600\n",
      "Epoch 164/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3197 - acc: 0.9300 - val_loss: 0.2060 - val_acc: 0.9600\n",
      "Epoch 165/500\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.3151 - acc: 0.8800 - val_loss: 0.2039 - val_acc: 0.9600\n",
      "Epoch 166/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.3434 - acc: 0.8400 - val_loss: 0.2019 - val_acc: 0.9600\n",
      "Epoch 167/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.3584 - acc: 0.8600 - val_loss: 0.1997 - val_acc: 0.9600\n",
      "Epoch 168/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3417 - acc: 0.8500 - val_loss: 0.1984 - val_acc: 0.9600\n",
      "Epoch 169/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3400 - acc: 0.8600 - val_loss: 0.1980 - val_acc: 0.9600\n",
      "Epoch 170/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3045 - acc: 0.9000 - val_loss: 0.1988 - val_acc: 0.9600\n",
      "Epoch 171/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.3392 - acc: 0.8600 - val_loss: 0.1995 - val_acc: 0.9600\n",
      "Epoch 172/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3010 - acc: 0.8900 - val_loss: 0.1998 - val_acc: 0.9600\n",
      "Epoch 173/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3201 - acc: 0.9000 - val_loss: 0.1982 - val_acc: 0.9600\n",
      "Epoch 174/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.3516 - acc: 0.8700 - val_loss: 0.1962 - val_acc: 0.9600\n",
      "Epoch 175/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.3122 - acc: 0.8800 - val_loss: 0.1922 - val_acc: 0.9600\n",
      "Epoch 176/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2786 - acc: 0.9400 - val_loss: 0.1883 - val_acc: 0.9600\n",
      "Epoch 177/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3279 - acc: 0.9000 - val_loss: 0.1856 - val_acc: 0.9800\n",
      "Epoch 178/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.3032 - acc: 0.9100 - val_loss: 0.1842 - val_acc: 0.9600\n",
      "Epoch 179/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.3604 - acc: 0.8800 - val_loss: 0.1838 - val_acc: 0.9600\n",
      "Epoch 180/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2881 - acc: 0.9400 - val_loss: 0.1830 - val_acc: 0.9600\n",
      "Epoch 181/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2931 - acc: 0.8900 - val_loss: 0.1823 - val_acc: 0.9600\n",
      "Epoch 182/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.3058 - acc: 0.8800 - val_loss: 0.1808 - val_acc: 0.9600\n",
      "Epoch 183/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.2979 - acc: 0.9200 - val_loss: 0.1784 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.3383 - acc: 0.8800 - val_loss: 0.1768 - val_acc: 0.9600\n",
      "Epoch 185/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2899 - acc: 0.9100 - val_loss: 0.1758 - val_acc: 0.9800\n",
      "Epoch 186/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.3067 - acc: 0.9200 - val_loss: 0.1755 - val_acc: 0.9800\n",
      "Epoch 187/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2991 - acc: 0.9000 - val_loss: 0.1753 - val_acc: 0.9600\n",
      "Epoch 188/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.2743 - acc: 0.9300 - val_loss: 0.1750 - val_acc: 0.9600\n",
      "Epoch 189/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2643 - acc: 0.9300 - val_loss: 0.1744 - val_acc: 0.9600\n",
      "Epoch 190/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2881 - acc: 0.9100 - val_loss: 0.1729 - val_acc: 0.9600\n",
      "Epoch 191/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2971 - acc: 0.8900 - val_loss: 0.1699 - val_acc: 0.9800\n",
      "Epoch 192/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2394 - acc: 0.9700 - val_loss: 0.1672 - val_acc: 0.9800\n",
      "Epoch 193/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.2683 - acc: 0.9400 - val_loss: 0.1652 - val_acc: 0.9600\n",
      "Epoch 194/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2988 - acc: 0.8800 - val_loss: 0.1637 - val_acc: 0.9600\n",
      "Epoch 195/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2527 - acc: 0.9100 - val_loss: 0.1622 - val_acc: 0.9600\n",
      "Epoch 196/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2556 - acc: 0.9400 - val_loss: 0.1605 - val_acc: 0.9600\n",
      "Epoch 197/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.3274 - acc: 0.8300 - val_loss: 0.1591 - val_acc: 0.9600\n",
      "Epoch 198/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.3042 - acc: 0.8800 - val_loss: 0.1579 - val_acc: 0.9600\n",
      "Epoch 199/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.3213 - acc: 0.8500 - val_loss: 0.1571 - val_acc: 0.9600\n",
      "Epoch 200/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.3116 - acc: 0.8700 - val_loss: 0.1570 - val_acc: 0.9800\n",
      "Epoch 201/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2431 - acc: 0.9200 - val_loss: 0.1568 - val_acc: 0.9800\n",
      "Epoch 202/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.2592 - acc: 0.9400 - val_loss: 0.1569 - val_acc: 0.9800\n",
      "Epoch 203/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2809 - acc: 0.9100 - val_loss: 0.1567 - val_acc: 0.9800\n",
      "Epoch 204/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2417 - acc: 0.9700 - val_loss: 0.1560 - val_acc: 0.9600\n",
      "Epoch 205/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.3030 - acc: 0.8700 - val_loss: 0.1543 - val_acc: 0.9800\n",
      "Epoch 206/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2597 - acc: 0.8900 - val_loss: 0.1524 - val_acc: 0.9800\n",
      "Epoch 207/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.2608 - acc: 0.9000 - val_loss: 0.1506 - val_acc: 0.9800\n",
      "Epoch 208/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2884 - acc: 0.8900 - val_loss: 0.1492 - val_acc: 0.9600\n",
      "Epoch 209/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2614 - acc: 0.9100 - val_loss: 0.1479 - val_acc: 0.9600\n",
      "Epoch 210/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.2286 - acc: 0.9400 - val_loss: 0.1464 - val_acc: 0.9600\n",
      "Epoch 211/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2888 - acc: 0.8900 - val_loss: 0.1451 - val_acc: 0.9800\n",
      "Epoch 212/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.2503 - acc: 0.9100 - val_loss: 0.1436 - val_acc: 0.9800\n",
      "Epoch 213/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.2826 - acc: 0.8700 - val_loss: 0.1423 - val_acc: 0.9800\n",
      "Epoch 214/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2589 - acc: 0.9200 - val_loss: 0.1411 - val_acc: 0.9800\n",
      "Epoch 215/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2408 - acc: 0.9400 - val_loss: 0.1400 - val_acc: 0.9800\n",
      "Epoch 216/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.2280 - acc: 0.9300 - val_loss: 0.1387 - val_acc: 0.9800\n",
      "Epoch 217/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2836 - acc: 0.8900 - val_loss: 0.1377 - val_acc: 0.9800\n",
      "Epoch 218/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2370 - acc: 0.9300 - val_loss: 0.1366 - val_acc: 0.9800\n",
      "Epoch 219/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2716 - acc: 0.9000 - val_loss: 0.1355 - val_acc: 0.9800\n",
      "Epoch 220/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.2300 - acc: 0.9700 - val_loss: 0.1343 - val_acc: 0.9800\n",
      "Epoch 221/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2384 - acc: 0.9200 - val_loss: 0.1330 - val_acc: 0.9800\n",
      "Epoch 222/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.2471 - acc: 0.9100 - val_loss: 0.1316 - val_acc: 0.9800\n",
      "Epoch 223/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2511 - acc: 0.9200 - val_loss: 0.1301 - val_acc: 0.9800\n",
      "Epoch 224/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2495 - acc: 0.9400 - val_loss: 0.1286 - val_acc: 0.9800\n",
      "Epoch 225/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2503 - acc: 0.9100 - val_loss: 0.1277 - val_acc: 0.9600\n",
      "Epoch 226/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.2217 - acc: 0.9100 - val_loss: 0.1269 - val_acc: 0.9600\n",
      "Epoch 227/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.2084 - acc: 0.9300 - val_loss: 0.1259 - val_acc: 0.9600\n",
      "Epoch 228/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.2639 - acc: 0.9000 - val_loss: 0.1255 - val_acc: 0.9800\n",
      "Epoch 229/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1956 - acc: 0.9400 - val_loss: 0.1251 - val_acc: 0.9800\n",
      "Epoch 230/500\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.2404 - acc: 0.9200 - val_loss: 0.1247 - val_acc: 0.9800\n",
      "Epoch 231/500\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.2319 - acc: 0.9400 - val_loss: 0.1242 - val_acc: 0.9800\n",
      "Epoch 232/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.2413 - acc: 0.8900 - val_loss: 0.1235 - val_acc: 0.9800\n",
      "Epoch 233/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2144 - acc: 0.9500 - val_loss: 0.1226 - val_acc: 0.9800\n",
      "Epoch 234/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2455 - acc: 0.9100 - val_loss: 0.1218 - val_acc: 0.9800\n",
      "Epoch 235/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.2583 - acc: 0.9400 - val_loss: 0.1213 - val_acc: 0.9600\n",
      "Epoch 236/500\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.2463 - acc: 0.8900 - val_loss: 0.1209 - val_acc: 0.9600\n",
      "Epoch 237/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2069 - acc: 0.9400 - val_loss: 0.1205 - val_acc: 0.9600\n",
      "Epoch 238/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2034 - acc: 0.9500 - val_loss: 0.1197 - val_acc: 0.9600\n",
      "Epoch 239/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2525 - acc: 0.9100 - val_loss: 0.1188 - val_acc: 0.9600\n",
      "Epoch 240/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.2263 - acc: 0.9000 - val_loss: 0.1180 - val_acc: 0.9600\n",
      "Epoch 241/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1703 - acc: 0.9500 - val_loss: 0.1169 - val_acc: 0.9600\n",
      "Epoch 242/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2367 - acc: 0.9200 - val_loss: 0.1162 - val_acc: 0.9800\n",
      "Epoch 243/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2223 - acc: 0.9500 - val_loss: 0.1168 - val_acc: 0.9800\n",
      "Epoch 244/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2050 - acc: 0.9600 - val_loss: 0.1176 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2436 - acc: 0.9400 - val_loss: 0.1189 - val_acc: 0.9800\n",
      "Epoch 246/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1797 - acc: 0.9300 - val_loss: 0.1195 - val_acc: 0.9800\n",
      "Epoch 247/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1855 - acc: 0.9300 - val_loss: 0.1180 - val_acc: 0.9800\n",
      "Epoch 248/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2234 - acc: 0.9200 - val_loss: 0.1153 - val_acc: 0.9800\n",
      "Epoch 249/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2339 - acc: 0.9100 - val_loss: 0.1146 - val_acc: 0.9800\n",
      "Epoch 250/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2239 - acc: 0.9100 - val_loss: 0.1150 - val_acc: 0.9600\n",
      "Epoch 251/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2368 - acc: 0.8800 - val_loss: 0.1154 - val_acc: 0.9600\n",
      "Epoch 252/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.2291 - acc: 0.9200 - val_loss: 0.1150 - val_acc: 0.9600\n",
      "Epoch 253/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1937 - acc: 0.9500 - val_loss: 0.1143 - val_acc: 0.9600\n",
      "Epoch 254/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2157 - acc: 0.9300 - val_loss: 0.1133 - val_acc: 0.9800\n",
      "Epoch 255/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2244 - acc: 0.9200 - val_loss: 0.1123 - val_acc: 0.9800\n",
      "Epoch 256/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.2158 - acc: 0.9200 - val_loss: 0.1114 - val_acc: 0.9800\n",
      "Epoch 257/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1983 - acc: 0.9500 - val_loss: 0.1104 - val_acc: 0.9800\n",
      "Epoch 258/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2216 - acc: 0.9300 - val_loss: 0.1096 - val_acc: 0.9800\n",
      "Epoch 259/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2543 - acc: 0.8700 - val_loss: 0.1094 - val_acc: 0.9800\n",
      "Epoch 260/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.2444 - acc: 0.9400 - val_loss: 0.1096 - val_acc: 0.9800\n",
      "Epoch 261/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2371 - acc: 0.9200 - val_loss: 0.1094 - val_acc: 0.9800\n",
      "Epoch 262/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1654 - acc: 0.9500 - val_loss: 0.1091 - val_acc: 0.9800\n",
      "Epoch 263/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2061 - acc: 0.8900 - val_loss: 0.1089 - val_acc: 0.9800\n",
      "Epoch 264/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1934 - acc: 0.9200 - val_loss: 0.1087 - val_acc: 0.9800\n",
      "Epoch 265/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1951 - acc: 0.9400 - val_loss: 0.1086 - val_acc: 0.9800\n",
      "Epoch 266/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2135 - acc: 0.9300 - val_loss: 0.1083 - val_acc: 0.9800\n",
      "Epoch 267/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1945 - acc: 0.9300 - val_loss: 0.1080 - val_acc: 0.9800\n",
      "Epoch 268/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1967 - acc: 0.9300 - val_loss: 0.1076 - val_acc: 0.9800\n",
      "Epoch 269/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2319 - acc: 0.9300 - val_loss: 0.1071 - val_acc: 0.9800\n",
      "Epoch 270/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.2263 - acc: 0.9500 - val_loss: 0.1063 - val_acc: 0.9800\n",
      "Epoch 271/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1780 - acc: 0.9600 - val_loss: 0.1051 - val_acc: 0.9800\n",
      "Epoch 272/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1467 - acc: 0.9600 - val_loss: 0.1041 - val_acc: 0.9800\n",
      "Epoch 273/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1795 - acc: 0.9700 - val_loss: 0.1032 - val_acc: 0.9800\n",
      "Epoch 274/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2014 - acc: 0.9400 - val_loss: 0.1026 - val_acc: 0.9800\n",
      "Epoch 275/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.2364 - acc: 0.9000 - val_loss: 0.1019 - val_acc: 0.9800\n",
      "Epoch 276/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2030 - acc: 0.9300 - val_loss: 0.1008 - val_acc: 0.9600\n",
      "Epoch 277/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1903 - acc: 0.9200 - val_loss: 0.0994 - val_acc: 0.9600\n",
      "Epoch 278/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1910 - acc: 0.9200 - val_loss: 0.0980 - val_acc: 0.9600\n",
      "Epoch 279/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1760 - acc: 0.9600 - val_loss: 0.0962 - val_acc: 0.9800\n",
      "Epoch 280/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1889 - acc: 0.9600 - val_loss: 0.0954 - val_acc: 0.9800\n",
      "Epoch 281/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1759 - acc: 0.9500 - val_loss: 0.0951 - val_acc: 0.9800\n",
      "Epoch 282/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1784 - acc: 0.9400 - val_loss: 0.0949 - val_acc: 0.9800\n",
      "Epoch 283/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2140 - acc: 0.9100 - val_loss: 0.0951 - val_acc: 0.9800\n",
      "Epoch 284/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1698 - acc: 0.9700 - val_loss: 0.0950 - val_acc: 0.9800\n",
      "Epoch 285/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1768 - acc: 0.9600 - val_loss: 0.0946 - val_acc: 0.9800\n",
      "Epoch 286/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1885 - acc: 0.9500 - val_loss: 0.0949 - val_acc: 0.9800\n",
      "Epoch 287/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1932 - acc: 0.9300 - val_loss: 0.0952 - val_acc: 0.9800\n",
      "Epoch 288/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1862 - acc: 0.9500 - val_loss: 0.0950 - val_acc: 0.9800\n",
      "Epoch 289/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1885 - acc: 0.9400 - val_loss: 0.0948 - val_acc: 0.9800\n",
      "Epoch 290/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1640 - acc: 0.9400 - val_loss: 0.0946 - val_acc: 0.9800\n",
      "Epoch 291/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1853 - acc: 0.9400 - val_loss: 0.0950 - val_acc: 0.9800\n",
      "Epoch 292/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1424 - acc: 0.9400 - val_loss: 0.0955 - val_acc: 0.9800\n",
      "Epoch 293/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1910 - acc: 0.9500 - val_loss: 0.0952 - val_acc: 0.9800\n",
      "Epoch 294/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.2342 - acc: 0.9200 - val_loss: 0.0945 - val_acc: 0.9800\n",
      "Epoch 295/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1998 - acc: 0.9400 - val_loss: 0.0939 - val_acc: 0.9800\n",
      "Epoch 296/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1689 - acc: 0.9500 - val_loss: 0.0928 - val_acc: 0.9800\n",
      "Epoch 297/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.2043 - acc: 0.9300 - val_loss: 0.0922 - val_acc: 0.9800\n",
      "Epoch 298/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1567 - acc: 0.9700 - val_loss: 0.0921 - val_acc: 0.9800\n",
      "Epoch 299/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1565 - acc: 0.9500 - val_loss: 0.0923 - val_acc: 0.9800\n",
      "Epoch 300/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1933 - acc: 0.9500 - val_loss: 0.0922 - val_acc: 0.9800\n",
      "Epoch 301/500\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.2031 - acc: 0.9300 - val_loss: 0.0920 - val_acc: 0.9800\n",
      "Epoch 302/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1988 - acc: 0.9300 - val_loss: 0.0918 - val_acc: 0.9600\n",
      "Epoch 303/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1982 - acc: 0.9500 - val_loss: 0.0919 - val_acc: 0.9600\n",
      "Epoch 304/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.2189 - acc: 0.9300 - val_loss: 0.0918 - val_acc: 0.9600\n",
      "Epoch 305/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2080 - acc: 0.9300 - val_loss: 0.0915 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.2093 - acc: 0.9300 - val_loss: 0.0913 - val_acc: 0.9800\n",
      "Epoch 307/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1698 - acc: 0.9300 - val_loss: 0.0912 - val_acc: 0.9800\n",
      "Epoch 308/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1466 - acc: 0.9500 - val_loss: 0.0912 - val_acc: 0.9800\n",
      "Epoch 309/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1653 - acc: 0.9600 - val_loss: 0.0913 - val_acc: 0.9800\n",
      "Epoch 310/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1593 - acc: 0.9500 - val_loss: 0.0913 - val_acc: 0.9800\n",
      "Epoch 311/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1602 - acc: 0.9500 - val_loss: 0.0910 - val_acc: 0.9800\n",
      "Epoch 312/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1609 - acc: 0.9500 - val_loss: 0.0900 - val_acc: 0.9800\n",
      "Epoch 313/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1806 - acc: 0.9300 - val_loss: 0.0886 - val_acc: 0.9800\n",
      "Epoch 314/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1546 - acc: 0.9600 - val_loss: 0.0874 - val_acc: 0.9800\n",
      "Epoch 315/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1644 - acc: 0.9800 - val_loss: 0.0862 - val_acc: 0.9800\n",
      "Epoch 316/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.2124 - acc: 0.9200 - val_loss: 0.0857 - val_acc: 0.9800\n",
      "Epoch 317/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2019 - acc: 0.9400 - val_loss: 0.0854 - val_acc: 0.9800\n",
      "Epoch 318/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1850 - acc: 0.9400 - val_loss: 0.0851 - val_acc: 0.9800\n",
      "Epoch 319/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1620 - acc: 0.9500 - val_loss: 0.0852 - val_acc: 0.9800\n",
      "Epoch 320/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1713 - acc: 0.9700 - val_loss: 0.0853 - val_acc: 0.9800\n",
      "Epoch 321/500\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.1782 - acc: 0.9700 - val_loss: 0.0859 - val_acc: 0.9800\n",
      "Epoch 322/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1613 - acc: 0.9600 - val_loss: 0.0860 - val_acc: 0.9800\n",
      "Epoch 323/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.2042 - acc: 0.9400 - val_loss: 0.0859 - val_acc: 0.9800\n",
      "Epoch 324/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2158 - acc: 0.9300 - val_loss: 0.0864 - val_acc: 0.9800\n",
      "Epoch 325/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1602 - acc: 0.9500 - val_loss: 0.0868 - val_acc: 0.9800\n",
      "Epoch 326/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1896 - acc: 0.9400 - val_loss: 0.0869 - val_acc: 0.9800\n",
      "Epoch 327/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1624 - acc: 0.9700 - val_loss: 0.0873 - val_acc: 0.9800\n",
      "Epoch 328/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1716 - acc: 0.9600 - val_loss: 0.0880 - val_acc: 0.9800\n",
      "Epoch 329/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1663 - acc: 0.9400 - val_loss: 0.0896 - val_acc: 0.9800\n",
      "Epoch 330/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1601 - acc: 0.9500 - val_loss: 0.0910 - val_acc: 0.9600\n",
      "Epoch 331/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1860 - acc: 0.9500 - val_loss: 0.0921 - val_acc: 0.9600\n",
      "Epoch 332/500\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.1888 - acc: 0.9400 - val_loss: 0.0905 - val_acc: 0.9600\n",
      "Epoch 333/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1609 - acc: 0.9600 - val_loss: 0.0887 - val_acc: 0.9800\n",
      "Epoch 334/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1723 - acc: 0.9300 - val_loss: 0.0876 - val_acc: 0.9800\n",
      "Epoch 335/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1791 - acc: 0.9400 - val_loss: 0.0884 - val_acc: 0.9800\n",
      "Epoch 336/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1765 - acc: 0.9700 - val_loss: 0.0899 - val_acc: 0.9800\n",
      "Epoch 337/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1857 - acc: 0.9500 - val_loss: 0.0911 - val_acc: 0.9800\n",
      "Epoch 338/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1788 - acc: 0.9300 - val_loss: 0.0908 - val_acc: 0.9800\n",
      "Epoch 339/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1538 - acc: 0.9500 - val_loss: 0.0895 - val_acc: 0.9800\n",
      "Epoch 340/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1649 - acc: 0.9700 - val_loss: 0.0870 - val_acc: 0.9800\n",
      "Epoch 341/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1893 - acc: 0.9600 - val_loss: 0.0844 - val_acc: 0.9800\n",
      "Epoch 342/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1776 - acc: 0.9700 - val_loss: 0.0828 - val_acc: 0.9800\n",
      "Epoch 343/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1880 - acc: 0.9400 - val_loss: 0.0822 - val_acc: 0.9800\n",
      "Epoch 344/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1842 - acc: 0.9600 - val_loss: 0.0835 - val_acc: 0.9600\n",
      "Epoch 345/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1316 - acc: 0.9900 - val_loss: 0.0856 - val_acc: 0.9600\n",
      "Epoch 346/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1207 - acc: 0.9600 - val_loss: 0.0858 - val_acc: 0.9600\n",
      "Epoch 347/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1826 - acc: 0.9300 - val_loss: 0.0847 - val_acc: 0.9600\n",
      "Epoch 348/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1300 - acc: 0.9600 - val_loss: 0.0836 - val_acc: 0.9600\n",
      "Epoch 349/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1534 - acc: 0.9800 - val_loss: 0.0817 - val_acc: 0.9600\n",
      "Epoch 350/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1392 - acc: 0.9600 - val_loss: 0.0807 - val_acc: 0.9800\n",
      "Epoch 351/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1654 - acc: 0.9100 - val_loss: 0.0805 - val_acc: 0.9800\n",
      "Epoch 352/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1740 - acc: 0.9300 - val_loss: 0.0809 - val_acc: 0.9800\n",
      "Epoch 353/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1685 - acc: 0.9400 - val_loss: 0.0816 - val_acc: 0.9800\n",
      "Epoch 354/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1446 - acc: 0.9400 - val_loss: 0.0825 - val_acc: 0.9800\n",
      "Epoch 355/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1585 - acc: 0.9300 - val_loss: 0.0825 - val_acc: 0.9800\n",
      "Epoch 356/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1679 - acc: 0.9200 - val_loss: 0.0824 - val_acc: 0.9800\n",
      "Epoch 357/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1834 - acc: 0.9300 - val_loss: 0.0821 - val_acc: 0.9800\n",
      "Epoch 358/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1513 - acc: 0.9500 - val_loss: 0.0817 - val_acc: 0.9800\n",
      "Epoch 359/500\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.1447 - acc: 0.9600 - val_loss: 0.0815 - val_acc: 0.9800\n",
      "Epoch 360/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1477 - acc: 0.9400 - val_loss: 0.0818 - val_acc: 0.9800\n",
      "Epoch 361/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1797 - acc: 0.9300 - val_loss: 0.0828 - val_acc: 0.9800\n",
      "Epoch 362/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1822 - acc: 0.9400 - val_loss: 0.0836 - val_acc: 0.9800\n",
      "Epoch 363/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1613 - acc: 0.9400 - val_loss: 0.0840 - val_acc: 0.9800\n",
      "Epoch 364/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1503 - acc: 0.9400 - val_loss: 0.0835 - val_acc: 0.9800\n",
      "Epoch 365/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1333 - acc: 0.9600 - val_loss: 0.0827 - val_acc: 0.9800\n",
      "Epoch 366/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1729 - acc: 0.9200 - val_loss: 0.0822 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1534 - acc: 0.9500 - val_loss: 0.0815 - val_acc: 0.9800\n",
      "Epoch 368/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1242 - acc: 0.9700 - val_loss: 0.0808 - val_acc: 0.9800\n",
      "Epoch 369/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1363 - acc: 0.9500 - val_loss: 0.0799 - val_acc: 0.9800\n",
      "Epoch 370/500\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.1235 - acc: 0.9700 - val_loss: 0.0787 - val_acc: 0.9800\n",
      "Epoch 371/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.1252 - acc: 0.9600 - val_loss: 0.0775 - val_acc: 0.9800\n",
      "Epoch 372/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1505 - acc: 0.9400 - val_loss: 0.0766 - val_acc: 0.9800\n",
      "Epoch 373/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1447 - acc: 0.9700 - val_loss: 0.0755 - val_acc: 0.9800\n",
      "Epoch 374/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1629 - acc: 0.9600 - val_loss: 0.0747 - val_acc: 0.9800\n",
      "Epoch 375/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1602 - acc: 0.9700 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 376/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1624 - acc: 0.9400 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 377/500\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.1631 - acc: 0.9400 - val_loss: 0.0747 - val_acc: 0.9800\n",
      "Epoch 378/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1585 - acc: 0.9300 - val_loss: 0.0756 - val_acc: 0.9600\n",
      "Epoch 379/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1413 - acc: 0.9700 - val_loss: 0.0764 - val_acc: 0.9800\n",
      "Epoch 380/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1326 - acc: 0.9600 - val_loss: 0.0768 - val_acc: 0.9800\n",
      "Epoch 381/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1208 - acc: 0.9700 - val_loss: 0.0771 - val_acc: 0.9800\n",
      "Epoch 382/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1716 - acc: 0.9400 - val_loss: 0.0776 - val_acc: 0.9800\n",
      "Epoch 383/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1343 - acc: 0.9600 - val_loss: 0.0779 - val_acc: 0.9800\n",
      "Epoch 384/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1126 - acc: 0.9900 - val_loss: 0.0783 - val_acc: 0.9800\n",
      "Epoch 385/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1742 - acc: 0.9400 - val_loss: 0.0791 - val_acc: 0.9800\n",
      "Epoch 386/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1317 - acc: 0.9800 - val_loss: 0.0798 - val_acc: 0.9800\n",
      "Epoch 387/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1445 - acc: 0.9700 - val_loss: 0.0796 - val_acc: 0.9800\n",
      "Epoch 388/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1079 - acc: 0.9700 - val_loss: 0.0788 - val_acc: 0.9800\n",
      "Epoch 389/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1750 - acc: 0.9500 - val_loss: 0.0777 - val_acc: 0.9800\n",
      "Epoch 390/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1680 - acc: 0.9400 - val_loss: 0.0761 - val_acc: 0.9800\n",
      "Epoch 391/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.2000 - acc: 0.9300 - val_loss: 0.0747 - val_acc: 0.9800\n",
      "Epoch 392/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1740 - acc: 0.9300 - val_loss: 0.0745 - val_acc: 0.9800\n",
      "Epoch 393/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1330 - acc: 0.9600 - val_loss: 0.0749 - val_acc: 0.9800\n",
      "Epoch 394/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1754 - acc: 0.9500 - val_loss: 0.0770 - val_acc: 0.9600\n",
      "Epoch 395/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1512 - acc: 0.9400 - val_loss: 0.0787 - val_acc: 0.9600\n",
      "Epoch 396/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1521 - acc: 0.9500 - val_loss: 0.0788 - val_acc: 0.9600\n",
      "Epoch 397/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1934 - acc: 0.9400 - val_loss: 0.0784 - val_acc: 0.9600\n",
      "Epoch 398/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1417 - acc: 0.9500 - val_loss: 0.0779 - val_acc: 0.9600\n",
      "Epoch 399/500\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.1248 - acc: 0.9800 - val_loss: 0.0772 - val_acc: 0.9800\n",
      "Epoch 400/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1181 - acc: 0.9700 - val_loss: 0.0762 - val_acc: 0.9800\n",
      "Epoch 401/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1395 - acc: 0.9800 - val_loss: 0.0755 - val_acc: 0.9800\n",
      "Epoch 402/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1643 - acc: 0.9300 - val_loss: 0.0749 - val_acc: 0.9800\n",
      "Epoch 403/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1369 - acc: 0.9800 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 404/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1452 - acc: 0.9400 - val_loss: 0.0738 - val_acc: 0.9800\n",
      "Epoch 405/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1148 - acc: 0.9900 - val_loss: 0.0731 - val_acc: 0.9800\n",
      "Epoch 406/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1362 - acc: 0.9800 - val_loss: 0.0726 - val_acc: 0.9800\n",
      "Epoch 407/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1343 - acc: 0.9600 - val_loss: 0.0725 - val_acc: 0.9800\n",
      "Epoch 408/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1336 - acc: 0.9600 - val_loss: 0.0725 - val_acc: 0.9600\n",
      "Epoch 409/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1443 - acc: 0.9600 - val_loss: 0.0719 - val_acc: 0.9600\n",
      "Epoch 410/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1362 - acc: 0.9600 - val_loss: 0.0705 - val_acc: 0.9600\n",
      "Epoch 411/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1541 - acc: 0.9800 - val_loss: 0.0693 - val_acc: 0.9800\n",
      "Epoch 412/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1159 - acc: 0.9800 - val_loss: 0.0685 - val_acc: 0.9800\n",
      "Epoch 413/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1582 - acc: 0.9600 - val_loss: 0.0686 - val_acc: 0.9800\n",
      "Epoch 414/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1108 - acc: 0.9700 - val_loss: 0.0684 - val_acc: 0.9800\n",
      "Epoch 415/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1448 - acc: 0.9400 - val_loss: 0.0681 - val_acc: 0.9800\n",
      "Epoch 416/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1298 - acc: 0.9400 - val_loss: 0.0675 - val_acc: 0.9800\n",
      "Epoch 417/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1597 - acc: 0.9500 - val_loss: 0.0672 - val_acc: 0.9800\n",
      "Epoch 418/500\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.1043 - acc: 0.9800 - val_loss: 0.0671 - val_acc: 0.9800\n",
      "Epoch 419/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1137 - acc: 0.9700 - val_loss: 0.0670 - val_acc: 0.9800\n",
      "Epoch 420/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1571 - acc: 0.9500 - val_loss: 0.0675 - val_acc: 0.9600\n",
      "Epoch 421/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.1310 - acc: 0.9500 - val_loss: 0.0677 - val_acc: 0.9600\n",
      "Epoch 422/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1178 - acc: 0.9500 - val_loss: 0.0675 - val_acc: 0.9600\n",
      "Epoch 423/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1464 - acc: 0.9600 - val_loss: 0.0676 - val_acc: 0.9800\n",
      "Epoch 424/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1072 - acc: 0.9600 - val_loss: 0.0678 - val_acc: 0.9800\n",
      "Epoch 425/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1361 - acc: 0.9600 - val_loss: 0.0685 - val_acc: 0.9800\n",
      "Epoch 426/500\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.1054 - acc: 0.9700 - val_loss: 0.0690 - val_acc: 0.9800\n",
      "Epoch 427/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1954 - acc: 0.9600 - val_loss: 0.0698 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.1297 - acc: 0.9600 - val_loss: 0.0704 - val_acc: 0.9800\n",
      "Epoch 429/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1091 - acc: 0.9900 - val_loss: 0.0710 - val_acc: 0.9800\n",
      "Epoch 430/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1314 - acc: 0.9600 - val_loss: 0.0717 - val_acc: 0.9800\n",
      "Epoch 431/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1180 - acc: 0.9600 - val_loss: 0.0718 - val_acc: 0.9800\n",
      "Epoch 432/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1294 - acc: 0.9500 - val_loss: 0.0719 - val_acc: 0.9800\n",
      "Epoch 433/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.1522 - acc: 0.9500 - val_loss: 0.0720 - val_acc: 0.9800\n",
      "Epoch 434/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1290 - acc: 0.9600 - val_loss: 0.0721 - val_acc: 0.9800\n",
      "Epoch 435/500\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.1249 - acc: 0.9900 - val_loss: 0.0723 - val_acc: 0.9800\n",
      "Epoch 436/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1040 - acc: 0.9600 - val_loss: 0.0722 - val_acc: 0.9800\n",
      "Epoch 437/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1282 - acc: 0.9500 - val_loss: 0.0723 - val_acc: 0.9800\n",
      "Epoch 438/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1012 - acc: 0.9600 - val_loss: 0.0724 - val_acc: 0.9800\n",
      "Epoch 439/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1067 - acc: 0.9900 - val_loss: 0.0717 - val_acc: 0.9800\n",
      "Epoch 440/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1126 - acc: 0.9600 - val_loss: 0.0709 - val_acc: 0.9800\n",
      "Epoch 441/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1305 - acc: 0.9400 - val_loss: 0.0702 - val_acc: 0.9800\n",
      "Epoch 442/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1603 - acc: 0.9300 - val_loss: 0.0694 - val_acc: 0.9800\n",
      "Epoch 443/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1410 - acc: 0.9600 - val_loss: 0.0686 - val_acc: 0.9800\n",
      "Epoch 444/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1620 - acc: 0.9600 - val_loss: 0.0678 - val_acc: 0.9800\n",
      "Epoch 445/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1547 - acc: 0.9800 - val_loss: 0.0673 - val_acc: 0.9800\n",
      "Epoch 446/500\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.1065 - acc: 0.9700 - val_loss: 0.0673 - val_acc: 0.9800\n",
      "Epoch 447/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1092 - acc: 0.9700 - val_loss: 0.0677 - val_acc: 0.9800\n",
      "Epoch 448/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1296 - acc: 0.9800 - val_loss: 0.0686 - val_acc: 0.9600\n",
      "Epoch 449/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1429 - acc: 0.9500 - val_loss: 0.0695 - val_acc: 0.9600\n",
      "Epoch 450/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1548 - acc: 0.9500 - val_loss: 0.0696 - val_acc: 0.9600\n",
      "Epoch 451/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1356 - acc: 0.9600 - val_loss: 0.0700 - val_acc: 0.9600\n",
      "Epoch 452/500\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.1969 - acc: 0.9000 - val_loss: 0.0699 - val_acc: 0.9600\n",
      "Epoch 453/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.0957 - acc: 0.9700 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "Epoch 454/500\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.1700 - acc: 0.9500 - val_loss: 0.0686 - val_acc: 0.9800\n",
      "Epoch 455/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1185 - acc: 0.9600 - val_loss: 0.0688 - val_acc: 0.9800\n",
      "Epoch 456/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1486 - acc: 0.9700 - val_loss: 0.0695 - val_acc: 0.9800\n",
      "Epoch 457/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1483 - acc: 0.9600 - val_loss: 0.0705 - val_acc: 0.9800\n",
      "Epoch 458/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1341 - acc: 0.9500 - val_loss: 0.0715 - val_acc: 0.9800\n",
      "Epoch 459/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1515 - acc: 0.9700 - val_loss: 0.0720 - val_acc: 0.9800\n",
      "Epoch 460/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1460 - acc: 0.9600 - val_loss: 0.0724 - val_acc: 0.9800\n",
      "Epoch 461/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1291 - acc: 0.9400 - val_loss: 0.0726 - val_acc: 0.9800\n",
      "Epoch 462/500\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.1193 - acc: 0.9700 - val_loss: 0.0725 - val_acc: 0.9800\n",
      "Epoch 463/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1293 - acc: 0.9600 - val_loss: 0.0717 - val_acc: 0.9800\n",
      "Epoch 464/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1173 - acc: 0.9800 - val_loss: 0.0706 - val_acc: 0.9800\n",
      "Epoch 465/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.0696 - val_acc: 0.9800\n",
      "Epoch 466/500\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.1498 - acc: 0.9800 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "Epoch 467/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1273 - acc: 0.9900 - val_loss: 0.0685 - val_acc: 0.9800\n",
      "Epoch 468/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1373 - acc: 0.9700 - val_loss: 0.0684 - val_acc: 0.9600\n",
      "Epoch 469/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1474 - acc: 0.9400 - val_loss: 0.0678 - val_acc: 0.9600\n",
      "Epoch 470/500\n",
      "100/100 [==============================] - 0s 36us/step - loss: 0.1197 - acc: 0.9700 - val_loss: 0.0678 - val_acc: 0.9600\n",
      "Epoch 471/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1232 - acc: 0.9800 - val_loss: 0.0672 - val_acc: 0.9600\n",
      "Epoch 472/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1247 - acc: 0.9600 - val_loss: 0.0672 - val_acc: 0.9600\n",
      "Epoch 473/500\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.1144 - acc: 0.9700 - val_loss: 0.0662 - val_acc: 0.9600\n",
      "Epoch 474/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1415 - acc: 0.9600 - val_loss: 0.0655 - val_acc: 0.9600\n",
      "Epoch 475/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1269 - acc: 0.9700 - val_loss: 0.0633 - val_acc: 0.9600\n",
      "Epoch 476/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1143 - acc: 0.9700 - val_loss: 0.0621 - val_acc: 0.9800\n",
      "Epoch 477/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1327 - acc: 0.9500 - val_loss: 0.0618 - val_acc: 0.9800\n",
      "Epoch 478/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1253 - acc: 0.9900 - val_loss: 0.0620 - val_acc: 0.9800\n",
      "Epoch 479/500\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.1102 - acc: 0.9900 - val_loss: 0.0622 - val_acc: 0.9800\n",
      "Epoch 480/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1152 - acc: 0.9700 - val_loss: 0.0627 - val_acc: 0.9800\n",
      "Epoch 481/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.0926 - acc: 0.9800 - val_loss: 0.0626 - val_acc: 0.9800\n",
      "Epoch 482/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.0953 - acc: 0.9700 - val_loss: 0.0623 - val_acc: 0.9800\n",
      "Epoch 483/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1008 - acc: 0.9700 - val_loss: 0.0621 - val_acc: 0.9800\n",
      "Epoch 484/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1328 - acc: 0.9700 - val_loss: 0.0623 - val_acc: 0.9800\n",
      "Epoch 485/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1478 - acc: 0.9700 - val_loss: 0.0620 - val_acc: 0.9800\n",
      "Epoch 486/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1217 - acc: 0.9500 - val_loss: 0.0616 - val_acc: 0.9800\n",
      "Epoch 487/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1400 - acc: 0.9400 - val_loss: 0.0617 - val_acc: 0.9800\n",
      "Epoch 488/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1364 - acc: 0.9700 - val_loss: 0.0627 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.0683 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9800\n",
      "Epoch 490/500\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.1201 - acc: 0.9500 - val_loss: 0.0633 - val_acc: 0.9800\n",
      "Epoch 491/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1284 - acc: 0.9800 - val_loss: 0.0634 - val_acc: 0.9800\n",
      "Epoch 492/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1140 - acc: 0.9700 - val_loss: 0.0635 - val_acc: 0.9800\n",
      "Epoch 493/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1238 - acc: 0.9800 - val_loss: 0.0623 - val_acc: 0.9800\n",
      "Epoch 494/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1353 - acc: 0.9700 - val_loss: 0.0615 - val_acc: 0.9800\n",
      "Epoch 495/500\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.1330 - acc: 0.9300 - val_loss: 0.0616 - val_acc: 0.9800\n",
      "Epoch 496/500\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.1481 - acc: 0.9500 - val_loss: 0.0620 - val_acc: 0.9800\n",
      "Epoch 497/500\n",
      "100/100 [==============================] - 0s 32us/step - loss: 0.1375 - acc: 0.9500 - val_loss: 0.0620 - val_acc: 0.9800\n",
      "Epoch 498/500\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.1054 - acc: 0.9900 - val_loss: 0.0617 - val_acc: 0.9800\n",
      "Epoch 499/500\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.1257 - acc: 0.9800 - val_loss: 0.0612 - val_acc: 0.9800\n",
      "Epoch 500/500\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.1203 - acc: 0.9700 - val_loss: 0.0606 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "epochs     = 500\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train_binary,\n",
    "    batch_size      = batch_size,\n",
    "    epochs          = epochs,\n",
    "    verbose         = 1,\n",
    "    validation_data = (x_test, y_test_binary),\n",
    "    callbacks       = [history]\n",
    ")\n",
    "\n",
    "score = model.evaluate(x_test, y_test_binary, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.06055693209171295\n",
      "test accuracy: 0.9799999904632568\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])\n",
    "plt.plot(range(1, epochs + 1), history.acc)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
