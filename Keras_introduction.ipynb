{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a more high-level neural network library than TensorFlow and can use TensorFlow as a backend, and is supported by the TensorFlow developers. Keras features implementations of neural network layers (including dropout, batch normalization and pooling), objectives, activation functions, optimizers, and features support for convolutional and recurrent neural networks. Keras is perhaps one of the better options for rapid prototyping of deep learning algorithms.\n",
    "\n",
    "Models in Keras are of two forms, Sequential and Functional API. The Sequential approach enables stacking of sequential and recurrent layers ordering from input to output while the Functional API approach enables more complicated arcitectures.\n",
    "\n",
    "Keras features callbacks utilities which can be used to track variables during training. These can be used to create checkpoints at which models are saved while training in case of crashes and whatnot. A callback class, which is a class that inherits from `keras.callbacks.Callback`, is passed to the model fitting function and could be used to log something like the accuracy as training is progressing. More specifically, `keras.callbacks.Callback` has methods that can be overridden in a callback class definition; methods such as the following:\n",
    "\n",
    "- `on_train_begin`\n",
    "- `on_epoch_end`\n",
    "- `on_batch_begin`\n",
    "- `on_batch_end`\n",
    "\n",
    "These are moments in training at which things can be done. Useful in overriding these methods is the `logs` dictionary which, by default, holds loss and accuracy during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# example: Keras 2D convolutional neural network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dimensions\n",
    "img_x       = 28\n",
    "img_y       = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data into training and testing datasets. The x data are the features and the y data are the labels.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data into a 4D tensor (sample_number, x_img_size, y_img_size, num_channels).\n",
    "# MNIST is greyscale, which corresponds to a single channel/dimension.\n",
    "# Alternatively, color, for example RGB, would correspond to three channels/dimensions.\n",
    "x_train     = x_train.reshape(x_train.shape[0], img_x, img_y, 1)\n",
    "x_test      = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "# Cast the data as type float32.\n",
    "x_train     = x_train.astype('float32')\n",
    "x_test      = x_test.astype('float32')\n",
    "x_train     = x_train / 255\n",
    "x_test      = x_test  / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices for use in the categorical_crossentropy loss.\n",
    "y_train     = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test      = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.49411765],\n",
       "        [0.53333336],\n",
       "        [0.6862745 ],\n",
       "        [0.10196079],\n",
       "        [0.6509804 ],\n",
       "        [1.        ],\n",
       "        [0.96862745],\n",
       "        [0.49803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.14117648],\n",
       "        [0.36862746],\n",
       "        [0.6039216 ],\n",
       "        [0.6666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.88235295],\n",
       "        [0.6745098 ],\n",
       "        [0.99215686],\n",
       "        [0.9490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19215687],\n",
       "        [0.93333334],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.9843137 ],\n",
       "        [0.3647059 ],\n",
       "        [0.32156864],\n",
       "        [0.32156864],\n",
       "        [0.21960784],\n",
       "        [0.15294118],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.7137255 ],\n",
       "        [0.96862745],\n",
       "        [0.94509804],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3137255 ],\n",
       "        [0.6117647 ],\n",
       "        [0.41960785],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8039216 ],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.16862746],\n",
       "        [0.6039216 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05490196],\n",
       "        [0.00392157],\n",
       "        [0.6039216 ],\n",
       "        [0.99215686],\n",
       "        [0.3529412 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.54509807],\n",
       "        [0.99215686],\n",
       "        [0.74509805],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04313726],\n",
       "        [0.74509805],\n",
       "        [0.99215686],\n",
       "        [0.27450982],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.13725491],\n",
       "        [0.94509804],\n",
       "        [0.88235295],\n",
       "        [0.627451  ],\n",
       "        [0.42352942],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.31764707],\n",
       "        [0.9411765 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.46666667],\n",
       "        [0.09803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1764706 ],\n",
       "        [0.7294118 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.5882353 ],\n",
       "        [0.10588235],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        [0.3647059 ],\n",
       "        [0.9882353 ],\n",
       "        [0.99215686],\n",
       "        [0.73333335],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.9764706 ],\n",
       "        [0.99215686],\n",
       "        [0.9764706 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.18039216],\n",
       "        [0.50980395],\n",
       "        [0.7176471 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8117647 ],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.5803922 ],\n",
       "        [0.8980392 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.98039216],\n",
       "        [0.7137255 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09411765],\n",
       "        [0.44705883],\n",
       "        [0.8666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7882353 ],\n",
       "        [0.30588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09019608],\n",
       "        [0.25882354],\n",
       "        [0.8352941 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.31764707],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.67058825],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7647059 ],\n",
       "        [0.3137255 ],\n",
       "        [0.03529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.6745098 ],\n",
       "        [0.8862745 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.52156866],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.53333336],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.83137256],\n",
       "        [0.5294118 ],\n",
       "        [0.5176471 ],\n",
       "        [0.0627451 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    x_train[5].reshape(28, 28),\n",
    "    cmap          = \"Greys\",\n",
    "    interpolation = \"nearest\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,087,106\n",
      "Trainable params: 1,087,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer to process the 2D input (image) data.\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        32,                       # number of output channels\n",
    "        kernel_size = (5, 5),     # kernel: 5 x 5 moving window\n",
    "        strides     = (1, 1),     # kernel strides in the x and y dimensions\n",
    "        activation  = 'relu',     # activation function: ReLU\n",
    "        input_shape = input_shape # input size/shape\n",
    "    )\n",
    ")\n",
    "# Add a 2D max pooling layer.\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size   = (2, 2),     # size of the pooling in the x and y dimensions\n",
    "        strides     = (2, 2)      # strides in the x and y dimensions\n",
    "    )\n",
    ")\n",
    "# Add a convolutional layer. The input tensor for this layer is (batch_size, 28, 28, 32),\n",
    "# where 28 x 28 corresponds to the input dimensions and 32 is the number of output channels from the previous layer.\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        64,                       # number of output channels\n",
    "        (5, 5),                   # kernel: 5 x 5 moving window\n",
    "        strides     = (1, 1),     # kernel strides in x and y dimensions -- default: (1, 1)\n",
    "        activation  = 'relu'      # activation function: ReLU\n",
    "    )\n",
    ")\n",
    "# Add a dropout layer.\n",
    "model.add(Dropout(0.5))\n",
    "# Add a 2D max pooling layer.\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size   = (2, 2)      # size of the pooling in the x and y dimensions\n",
    "    )\n",
    ")\n",
    "# Flatten the output from convolutional layers to prepare them for input to fully-connected layers.\n",
    "model.add(Flatten())\n",
    "# Specify a fully-connected layer.\n",
    "model.add(\n",
    "    Dense(\n",
    "        1000,                     # number of nodes\n",
    "        activation  = 'relu'      # activation function: ReLU\n",
    "    )\n",
    ")\n",
    "# Specify a fully-connected output layer.\n",
    "model.add(\n",
    "    Dense(\n",
    "        num_classes,              # number of classes\n",
    "        activation  = 'softmax'   # softmax classification\n",
    "    )\n",
    ")\n",
    "plot_model(model, to_file=\"model.png\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss            = keras.losses.categorical_crossentropy,\n",
    "    optimizer       = keras.optimizers.Adam(), # alternative: keras.optimizers.SGD(lr = 0.01)\n",
    "    metrics         = ['accuracy']\n",
    ")\n",
    "\n",
    "# Define a callback class which is to be passed to the model fitting function\n",
    "# as an element of a list of possible callbacks.\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.acc = []\n",
    "    def on_epoch_end(self, batch, logs = {}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath       = 'best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "    monitor        = 'val_loss',\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2928 - acc: 0.9107 - val_loss: 0.0896 - val_acc: 0.9793\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0707 - acc: 0.9785 - val_loss: 0.0669 - val_acc: 0.9846\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0477 - acc: 0.9852 - val_loss: 0.0484 - val_acc: 0.9883\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0384 - acc: 0.9879 - val_loss: 0.0443 - val_acc: 0.9900\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0323 - acc: 0.9902 - val_loss: 0.0338 - val_acc: 0.9903\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0271 - acc: 0.9913 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0318 - val_acc: 0.9911\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0280 - val_acc: 0.9924\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0193 - acc: 0.9938 - val_loss: 0.0230 - val_acc: 0.9932\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0271 - val_acc: 0.9914\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0274 - val_acc: 0.9923\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0211 - val_acc: 0.9938\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0125 - acc: 0.9959 - val_loss: 0.0207 - val_acc: 0.9935\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0119 - acc: 0.9960 - val_loss: 0.0205 - val_acc: 0.9933\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0119 - acc: 0.9957 - val_loss: 0.0199 - val_acc: 0.9940\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0175 - val_acc: 0.9940\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0227 - val_acc: 0.9931\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0199 - val_acc: 0.9942\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0199 - val_acc: 0.9935\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0243 - val_acc: 0.9918\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0185 - val_acc: 0.9935\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0192 - val_acc: 0.9937\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0242 - val_acc: 0.9923\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0212 - val_acc: 0.9933\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0208 - val_acc: 0.9933\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0205 - val_acc: 0.9934\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0209 - val_acc: 0.9935\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0185 - val_acc: 0.9939\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0060 - acc: 0.9978 - val_loss: 0.0225 - val_acc: 0.9931\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0226 - val_acc: 0.9931\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0188 - val_acc: 0.9937\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0191 - val_acc: 0.9941\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0226 - val_acc: 0.9935\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9940\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0211 - val_acc: 0.9939\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0207 - val_acc: 0.9941\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0245 - val_acc: 0.9939\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0227 - val_acc: 0.9925\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0239 - val_acc: 0.9939\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0184 - val_acc: 0.9945\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0202 - val_acc: 0.9943\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0240 - val_acc: 0.9938\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0172 - val_acc: 0.9945\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0181 - val_acc: 0.9939\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0226 - val_acc: 0.9935\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0036 - acc: 0.9986 - val_loss: 0.0189 - val_acc: 0.9944\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0209 - val_acc: 0.9940\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0203 - val_acc: 0.9946\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size      = 512,\n",
    "    epochs          = epochs,\n",
    "    verbose         = 1,\n",
    "    validation_data = (x_test, y_test),\n",
    "    callbacks       = [history, checkpoint]\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.02034617946599842\n",
      "test accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])\n",
    "plt.plot(range(1, epochs + 1), history.acc)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
