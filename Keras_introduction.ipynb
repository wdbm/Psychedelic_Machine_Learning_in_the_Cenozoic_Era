{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a more high-level neural network library than TensorFlow and can use TensorFlow as a backend, and is supported by the TensorFlow developers. Keras features implementations of neural network layers (including dropout, batch normalization and pooling), objectives, activation functions, optimizers, and features support for convolutional and recurrent neural networks. Keras is perhaps one of the better options for rapid prototyping of deep learning algorithms.\n",
    "\n",
    "Models in Keras are of two forms, Sequential and Functional API. The Sequential approach enables stacking of sequential and recurrent layers ordering from input to output while the Functional API approach enables more complicated arcitectures.\n",
    "\n",
    "Keras features callbacks utilities which can be used to track variables during training. These can be used to create checkpoints at which models are saved while training in case of crashes and whatnot. A callback class, which is a class that inherits from `keras.callbacks.Callback`, is passed to the model fitting function and could be used to log something like the accuracy as training is progressing. More specifically, `keras.callbacks.Callback` has methods that can be overridden in a callback class definition; methods such as the following:\n",
    "\n",
    "- `on_train_begin`\n",
    "- `on_epoch_end`\n",
    "- `on_batch_begin`\n",
    "- `on_batch_end`\n",
    "\n",
    "These are moments in training at which things can be done. Useful in overriding these methods is the `logs` dictionary which, by default, holds loss and accuracy during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# example: Keras 2D convolutional neural network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dimensions\n",
    "img_x       = 28\n",
    "img_y       = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data into training and testing datasets. The x data are the features and the y data are the labels.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data into a 4D tensor (sample_number, x_img_size, y_img_size, num_channels).\n",
    "# MNIST is greyscale, which corresponds to a single channel/dimension.\n",
    "# Alternatively, color, for example RGB, would correspond to three channels/dimensions.\n",
    "x_train     = x_train.reshape(x_train.shape[0], img_x, img_y, 1)\n",
    "x_test      = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "# Cast the data as type float32.\n",
    "x_train     = x_train.astype('float32')\n",
    "x_test      = x_test.astype('float32')\n",
    "x_train     = x_train / 255\n",
    "x_test      = x_test  / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices for use in the categorical_crossentropy loss.\n",
    "y_train     = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test      = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.49411765],\n",
       "        [0.53333336],\n",
       "        [0.6862745 ],\n",
       "        [0.10196079],\n",
       "        [0.6509804 ],\n",
       "        [1.        ],\n",
       "        [0.96862745],\n",
       "        [0.49803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.14117648],\n",
       "        [0.36862746],\n",
       "        [0.6039216 ],\n",
       "        [0.6666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.88235295],\n",
       "        [0.6745098 ],\n",
       "        [0.99215686],\n",
       "        [0.9490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19215687],\n",
       "        [0.93333334],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.9843137 ],\n",
       "        [0.3647059 ],\n",
       "        [0.32156864],\n",
       "        [0.32156864],\n",
       "        [0.21960784],\n",
       "        [0.15294118],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.7137255 ],\n",
       "        [0.96862745],\n",
       "        [0.94509804],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3137255 ],\n",
       "        [0.6117647 ],\n",
       "        [0.41960785],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8039216 ],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.16862746],\n",
       "        [0.6039216 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05490196],\n",
       "        [0.00392157],\n",
       "        [0.6039216 ],\n",
       "        [0.99215686],\n",
       "        [0.3529412 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.54509807],\n",
       "        [0.99215686],\n",
       "        [0.74509805],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04313726],\n",
       "        [0.74509805],\n",
       "        [0.99215686],\n",
       "        [0.27450982],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.13725491],\n",
       "        [0.94509804],\n",
       "        [0.88235295],\n",
       "        [0.627451  ],\n",
       "        [0.42352942],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.31764707],\n",
       "        [0.9411765 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.46666667],\n",
       "        [0.09803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1764706 ],\n",
       "        [0.7294118 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.5882353 ],\n",
       "        [0.10588235],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        [0.3647059 ],\n",
       "        [0.9882353 ],\n",
       "        [0.99215686],\n",
       "        [0.73333335],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.9764706 ],\n",
       "        [0.99215686],\n",
       "        [0.9764706 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.18039216],\n",
       "        [0.50980395],\n",
       "        [0.7176471 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8117647 ],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.5803922 ],\n",
       "        [0.8980392 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.98039216],\n",
       "        [0.7137255 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09411765],\n",
       "        [0.44705883],\n",
       "        [0.8666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7882353 ],\n",
       "        [0.30588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09019608],\n",
       "        [0.25882354],\n",
       "        [0.8352941 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.31764707],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.67058825],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7647059 ],\n",
       "        [0.3137255 ],\n",
       "        [0.03529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.6745098 ],\n",
       "        [0.8862745 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.52156866],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.53333336],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.83137256],\n",
       "        [0.5294118 ],\n",
       "        [0.5176471 ],\n",
       "        [0.0627451 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,087,106\n",
      "Trainable params: 1,087,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer to process the 2D input (image) data.\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        32,                       # number of output channels\n",
    "        kernel_size = (5, 5),     # kernel: 5 x 5 moving window\n",
    "        strides     = (1, 1),     # kernel strides in the x and y dimensions\n",
    "        activation  = 'relu',     # activation function: ReLU\n",
    "        input_shape = input_shape # input size/shape\n",
    "    )\n",
    ")\n",
    "# Add a 2D max pooling layer.\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size   = (2, 2),     # size of the pooling in the x and y dimensions\n",
    "        strides     = (2, 2)      # strides in the x and y dimensions\n",
    "    )\n",
    ")\n",
    "# Add a convolutional layer. The input tensor for this layer is (batch_size, 28, 28, 32),\n",
    "# where 28 x 28 corresponds to the input dimensions and 32 is the number of output channels from the previous layer.\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        64,                       # number of output channels\n",
    "        (5, 5),                   # kernel: 5 x 5 moving window\n",
    "        strides     = (1, 1),     # kernel strides in x and y dimensions -- default: (1, 1)\n",
    "        activation  = 'relu'      # activation function: ReLU\n",
    "    )\n",
    ")\n",
    "# Add a dropout layer.\n",
    "model.add(Dropout(0.5))\n",
    "# Add a 2D max pooling layer.\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size   = (2, 2)      # size of the pooling in the x and y dimensions\n",
    "    )\n",
    ")\n",
    "# Flatten the output from convolutional layers to prepare them for input to fully-connected layers.\n",
    "model.add(Flatten())\n",
    "# Specify a fully-connected layer.\n",
    "model.add(\n",
    "    Dense(\n",
    "        1000,                     # number of nodes\n",
    "        activation  = 'relu'      # activation function: ReLU\n",
    "    )\n",
    ")\n",
    "# Specify a fully-connected output layer.\n",
    "model.add(\n",
    "    Dense(\n",
    "        num_classes,              # number of classes\n",
    "        activation  = 'softmax'   # softmax classification\n",
    "    )\n",
    ")\n",
    "plot_model(model, to_file=\"model.png\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss            = keras.losses.categorical_crossentropy,\n",
    "    optimizer       = keras.optimizers.Adam(), # alternative: keras.optimizers.SGD(lr = 0.01)\n",
    "    metrics         = ['accuracy']\n",
    ")\n",
    "\n",
    "# Define a callback class which is to be passed to the model fitting function\n",
    "# as an element of a list of possible callbacks.\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.acc = []\n",
    "    def on_epoch_end(self, batch, logs = {}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath       = 'best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "    monitor        = 'val_loss',\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2944 - acc: 0.9145 - val_loss: 0.0876 - val_acc: 0.9816\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0686 - acc: 0.9788 - val_loss: 0.0600 - val_acc: 0.9859\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0487 - acc: 0.9849 - val_loss: 0.0450 - val_acc: 0.9892\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.0353 - val_acc: 0.9912\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0305 - acc: 0.9907 - val_loss: 0.0405 - val_acc: 0.9889\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0285 - acc: 0.9900 - val_loss: 0.0301 - val_acc: 0.9911\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0269 - val_acc: 0.9913\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0268 - val_acc: 0.9917\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0222 - val_acc: 0.9937\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0202 - val_acc: 0.9931\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0137 - acc: 0.9951 - val_loss: 0.0208 - val_acc: 0.9933\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0183 - val_acc: 0.9944\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0234 - val_acc: 0.9921\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0210 - val_acc: 0.9936\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0281 - val_acc: 0.9913\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0193 - val_acc: 0.9933\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0213 - val_acc: 0.9930\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0178 - val_acc: 0.9940\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0223 - val_acc: 0.9931\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0187 - val_acc: 0.9937\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0198 - val_acc: 0.9937\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0206 - val_acc: 0.9938\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0197 - val_acc: 0.9937\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0190 - val_acc: 0.9936\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0246 - val_acc: 0.9924\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0069 - acc: 0.9974 - val_loss: 0.0215 - val_acc: 0.9930\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0214 - val_acc: 0.9926\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0193 - val_acc: 0.9940\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0186 - val_acc: 0.9936\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.0221 - val_acc: 0.9940\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0213 - val_acc: 0.9934\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0201 - val_acc: 0.9934\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0168 - val_acc: 0.9943\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0242 - val_acc: 0.9933\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0241 - val_acc: 0.9932\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0214 - val_acc: 0.9931\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0193 - val_acc: 0.9939\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0235 - val_acc: 0.9926\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0183 - val_acc: 0.9944\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0237 - val_acc: 0.9933\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0202 - val_acc: 0.9940\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0204 - val_acc: 0.9941\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0199 - val_acc: 0.9946\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0194 - val_acc: 0.9946\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0215 - val_acc: 0.9943\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0241 - val_acc: 0.9930\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0208 - val_acc: 0.9936\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size      = 512,\n",
    "    epochs          = epochs,\n",
    "    verbose         = 1,\n",
    "    validation_data = (x_test, y_test),\n",
    "    callbacks       = [history, checkpoint]\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.02079192531554181\n",
      "test accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])\n",
    "plt.plot(range(1, epochs + 1), history.acc)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
